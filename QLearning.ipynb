{
 "metadata": {
  "name": "",
  "signature": "sha256:10895643d09dee5ae816d194a69e1c7f5a5d72764475cf17dbc26c207f27dadf"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import numpy as np\n",
      "from numpy.random import rand\n",
      "import math\n",
      "from random import randint\n",
      "import itertools\n",
      "import matplotlib.pyplot as plt\n",
      "%matplotlib inline"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 1
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "class ConnectN:\n",
      "    \n",
      "    def __init__(self, grid_size, n):\n",
      "        self.n = n\n",
      "        self.grid_size = grid_size\n",
      "        self.grid = np.zeros([grid_size,grid_size])\n",
      "        self.finished = 0\n",
      "        \n",
      "    def reset(self):\n",
      "        self.__init__(self.grid_size, self.n)\n",
      "\n",
      "    def check_win(self, col, row, player):\n",
      "        for i in range(0, self.n):\n",
      "            if sum(self.grid[col, row - i:row - i + self.n]) == self.n*player:\n",
      "                self.finished = 1\n",
      "                return 1\n",
      "            if sum(self.grid[col - i: col - i + self.n, row]) == self.n*player:\n",
      "                self.finished = 1\n",
      "                return 1\n",
      "            if col - i >= 0 and col - i + self.n - 1 < self.grid_size and row - i >= 0 and row - i + self.n - 1 < self.grid_size:\n",
      "                if sum([self.grid[col - i + x, row - i + x] for x in range(0, self.n)]) == self.n*player:\n",
      "                    self.finished = 1\n",
      "                    return 1\n",
      "            if col - i >= 0 and col - i + self.n - 1 < self.grid_size and row + i >= 0 and row + i - self.n + 1 < self.grid_size:\n",
      "                if sum([self.grid[col - i + x, row + i - x] for x in range(0, self.n)]) == self.n*player:\n",
      "                    self.finished = 1\n",
      "                    return 1\n",
      "        return 0\n",
      "\n",
      "    def move(self, col, player):\n",
      "        # first value is return message, second value is reward\n",
      "        if self.finished == 1:\n",
      "            return 1, 0\n",
      "        sum_col = np.sum([abs(x) for x in self.grid[col]])\n",
      "        if sum_col == self.grid_size:\n",
      "            return -1, -1\n",
      "        self.grid[col, sum_col] = player\n",
      "        if self.check_win(col, sum_col, player) == 1:\n",
      "            return 1, 50\n",
      "        return 0, 0\n",
      "        \n",
      "    def print_grid(self):\n",
      "        print(np.rot90(self.grid))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 149
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "x = ConnectN(6,3)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 150
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "x.move(5, -1)[0]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 151,
       "text": [
        "0"
       ]
      }
     ],
     "prompt_number": 151
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def grid_to_key(grid):\n",
      "\n",
      "    key = \"\"\n",
      "\n",
      "    for row in np.rot90(grid):\n",
      "        for column in row:\n",
      "            key += str(int(column))\n",
      "\n",
      "    return key"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 152
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "grid_to_key(x.grid)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 153,
       "text": [
        "'00000000000000000000000000000000000-1'"
       ]
      }
     ],
     "prompt_number": 153
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "class CustomDict(dict):\n",
      "    \n",
      "    def __init__(self, num_states, *arg, **kw):\n",
      "        self.num_states = num_states\n",
      "        super(CustomDict, self).__init__(*arg, **kw)\n",
      "        \n",
      "    def __getitem__(self, key):\n",
      "        \n",
      "        if key not in self.__dict__:\n",
      "            dict.__setitem__(self, key, np.zeros(self.num_states))\n",
      "        return dict.__getitem__(self, key)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 154
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def run_trial(agent, MIN_ITERATIONS, MIN_EPISODES, player):\n",
      "    \n",
      "    rewards_by_iteration = []\n",
      "    rewards_by_episode = []\n",
      "    cumu_rewards_by_iteration = []\n",
      "    cumu_rewards_by_episode = []\n",
      "    \n",
      "    iteration = episode = 0\n",
      "    agent.reset()\n",
      "\n",
      "    while iteration < MIN_ITERATIONS or episode < MIN_EPISODES:\n",
      "        \n",
      "        task.reset()\n",
      "        board_state = task.grid\n",
      "        reward = None\n",
      "        cumulative_reward = 0\n",
      "\n",
      "        while iteration < MIN_ITERATIONS or episode < MIN_EPISODES:\n",
      "                        \n",
      "            action = agent.interact(reward, board_state, iteration)[0]\n",
      "\n",
      "            print np.rot90(task.grid)\n",
      "\n",
      "            if task.move(action, player)[0] == 1:\n",
      "                break\n",
      "\n",
      "            # Take action A, observe R, S'.\n",
      "            return_val, reward = task.move(action, player)\n",
      "\n",
      "            # Log rewards.\n",
      "            if iteration < MIN_ITERATIONS:\n",
      "                rewards_by_iteration.append(reward)\n",
      "                if cumu_rewards_by_iteration == []:\n",
      "                    cumu_rewards_by_iteration.append(reward)\n",
      "                else:\n",
      "                    cumu_rewards_by_iteration.append(cumu_rewards_by_iteration[-1] + reward)\n",
      "                \n",
      "            cumulative_reward += reward\n",
      "\n",
      "            iteration += 1\n",
      "\n",
      "        if episode < MIN_EPISODES:\n",
      "            rewards_by_episode.append(cumulative_reward)\n",
      "            if cumu_rewards_by_episode == []:\n",
      "                cumu_rewards_by_episode.append(cumulative_reward)\n",
      "            else:\n",
      "                cumu_rewards_by_episode.append(cumu_rewards_by_episode[-1] + cumulative_reward)\n",
      "        episode += 1\n",
      "        \n",
      "    return rewards_by_iteration, rewards_by_episode, cumu_rewards_by_iteration, cumu_rewards_by_episode"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 155
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "class TD_Learner(object):\n",
      "    \"\"\"\n",
      "    Base class for Temporal Difference Learners, like Sarsa and Q learning.\n",
      "    \"\"\"\n",
      "    \n",
      "    def __init__(self, task, epsilon=.1, discount_factor=.9, learning_rate=.5):\n",
      "        \n",
      "        self.num_states = task.grid_size\n",
      "        self.num_actions = task.grid_size\n",
      "        self.epsilon = epsilon\n",
      "        self.discount_factor = discount_factor\n",
      "        self.learning_rate = learning_rate\n",
      "        self.value_table = CustomDict(self.num_states)\n",
      "\n",
      "#         for key in itertools.product([0, 1, -1], repeat=self.num_states*self.num_states):\n",
      "#             str_key = \"\".join(map(str, key))\n",
      "#             self.value_table[str_key] = np.zeros(self.num_states)\n",
      "            \n",
      "        self.reset()\n",
      "\n",
      "    def reset(self):\n",
      "        self.last_board_state = None\n",
      "        self.last_action = None\n",
      "        self.value_table = CustomDict(self.num_states)\n",
      "        \n",
      "#         for key in itertools.combinations_with_replacement([0, 1, -1], self.num_states*self.num_states):\n",
      "#             str_key = \"\".join(map(str, key))\n",
      "#             self.value_table[str_key] = np.zeros(self.num_states)\n",
      "\n",
      "    \n",
      "    def softmax(self, next_board_state):\n",
      "        \n",
      "        def weighted_pick(weights,n_picks):\n",
      "            t = np.cumsum(weights)\n",
      "            s = sum(weights)\n",
      "            return np.searchsorted(t,rand(n_picks)*s)\n",
      "\n",
      "        tau = .5\n",
      "        num = math.e**(self.value_table[grid_to_key(next_board_state)]/tau)\n",
      "        probs = num/sum(num)\n",
      "        best_action = weighted_pick(probs, 1)\n",
      "                \n",
      "        return best_action\n",
      "        "
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 156
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "class Q_Learner(TD_Learner):\n",
      "    \"\"\"\n",
      "    Implementation of Q Learning, inheriting from TD Learner base class. \n",
      "    \"\"\"\n",
      "    \n",
      "    def __init__(self, task, epsilon=.1, discount_factor=.9, learning_rate=.5):   \n",
      "        TD_Learner.__init__(self, task, epsilon, discount_factor, learning_rate) \n",
      "                                                \n",
      "\n",
      "    def interact(self, reward, next_board_state, num_iterations):\n",
      "        \n",
      "        if isinstance(self.learning_rate, int) or isinstance(self.learning_rate, float):\n",
      "            this_iter_learning_rate = self.learning_rate\n",
      "        else:        \n",
      "            this_iter_learning_rate = self.learning_rate(num_iterations)\n",
      "\n",
      "        if reward is None:\n",
      "            next_action = self.softmax(next_board_state)\n",
      "\n",
      "            self.last_board_state = next_board_state\n",
      "            self.last_action = next_action\n",
      "            return self.last_action\n",
      "                \n",
      "        if reward == 50:\n",
      "            delta = delta = reward - self.value_table[grid_to_key(self.last_board_state)][self.last_action]\n",
      "            self.value_table[grid_to_key(self.last_board_state)][self.last_action] += this_iter_learning_rate * delta\n",
      "            print \"Won!\"\n",
      "            return self.last_action\n",
      "        \n",
      "        draw = np.random.uniform(0,1,1)\n",
      "\n",
      "        if draw < self.epsilon:\n",
      "            next_action = self.softmax(next_board_state)\n",
      "        else:\n",
      "            next_action = np.argmax(self.value_table[grid_to_key(next_board_state)])\n",
      "\n",
      "        # Update value function.\n",
      "        delta = reward + self.discount_factor * np.amax(self.value_table[grid_to_key(next_board_state)]) - self.value_table[grid_to_key(self.last_board_state)][self.last_action]\n",
      "        self.value_table[grid_to_key(self.last_board_state)][self.last_action] += this_iter_learning_rate * delta\n",
      "\n",
      "        # Eligibility traces\n",
      "#         for i in range(0, self.num_states):\n",
      "#             for j in range(0, self.num_actions):\n",
      "#                 self.value_table[i, j] += this_iter_learning_rate * delta * self.e[i,j]\n",
      "#                 if self.last_action == j:\n",
      "#                     self.e[i, j] = self.discount_factor * self.trace_size * self.e[i,j]\n",
      "#                 else:\n",
      "#                     self.e[i, j] = 0\n",
      "                    \n",
      "        self.last_board_state = next_board_state\n",
      "        self.last_action = next_action\n",
      "\n",
      "        return self.last_action\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 157
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "task = ConnectN(3,2)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 165
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "res = run_trial(Q_Learner(task), 2, 0, 1)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "[[ 0.  0.  0.]\n",
        " [ 0.  0.  0.]\n",
        " [ 0.  0.  0.]]\n",
        "Won!\n",
        "[[ 0.  0.  0.]\n",
        " [ 0.  0.  1.]\n",
        " [ 0.  0.  1.]]\n",
        "[[ 0.  0.  0.]\n",
        " [ 0.  0.  0.]\n",
        " [ 0.  0.  0.]]\n"
       ]
      }
     ],
     "prompt_number": 166
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "task = ConnectN(5,3)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 161
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "res = run_trial(Q_Learner(task), 2, 0, 1)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "[[ 0.  0.  0.  0.  0.]\n",
        " [ 0.  0.  0.  0.  0.]\n",
        " [ 0.  0.  0.  0.  0.]\n",
        " [ 0.  0.  0.  0.  0.]\n",
        " [ 0.  0.  0.  0.  0.]]\n"
       ]
      },
      {
       "ename": "IndexError",
       "evalue": "invalid index to scalar variable.",
       "output_type": "pyerr",
       "traceback": [
        "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
        "\u001b[0;32m<ipython-input-163-e32d6088a5b6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrun_trial\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mQ_Learner\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
        "\u001b[0;32m<ipython-input-155-d2944d3b50a4>\u001b[0m in \u001b[0;36mrun_trial\u001b[0;34m(agent, MIN_ITERATIONS, MIN_EPISODES, player)\u001b[0m\n\u001b[1;32m     18\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0miteration\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mMIN_ITERATIONS\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mepisode\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mMIN_EPISODES\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m             \u001b[0maction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0magent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minteract\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreward\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mboard_state\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miteration\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m             \u001b[0;32mprint\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrot90\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtask\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
        "\u001b[0;31mIndexError\u001b[0m: invalid index to scalar variable."
       ]
      }
     ],
     "prompt_number": 163
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}