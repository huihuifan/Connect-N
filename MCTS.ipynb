{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Monte Carlo Tree Search - Andre Nguyen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from __future__ import division\n",
    "import numpy as np\n",
    "from numpy.random import rand\n",
    "import math\n",
    "from random import randint\n",
    "import itertools\n",
    "import matplotlib.pyplot as plt\n",
    "import copy\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Ken's break ties function.\n",
    "def argmax_breaking_ties_randomly(x):\n",
    "    max_value = np.max(x)\n",
    "    indices_with_max_value = np.flatnonzero(x == max_value)\n",
    "    return np.random.choice(indices_with_max_value)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Angela's Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class ConnectN:\n",
    "    \n",
    "    def __init__(self, grid_size, n):\n",
    "        self.n = n\n",
    "        self.grid_size = grid_size\n",
    "        self.grid = np.zeros([grid_size,grid_size])\n",
    "        self.finished = 0\n",
    "        self.turn_num = 0\n",
    "        \n",
    "    def reset(self):\n",
    "        self.__init__(self.grid_size, self.n)\n",
    "\n",
    "    def check_win(self, col, row, player):\n",
    "        for i in range(0, self.n):\n",
    "            if sum(self.grid[col, row - i:row - i + self.n]) == self.n*player:\n",
    "                self.finished = 1\n",
    "                return 1\n",
    "            if sum(self.grid[col - i: col - i + self.n, row]) == self.n*player:\n",
    "                self.finished = 1\n",
    "                return 1\n",
    "            if col - i >= 0 and col - i + self.n - 1 < self.grid_size and row - i >= 0 and row - i + self.n - 1 < self.grid_size:\n",
    "                if sum([self.grid[col - i + x, row - i + x] for x in range(0, self.n)]) == self.n*player:\n",
    "                    self.finished = 1\n",
    "                    return 1\n",
    "            if col - i >= 0 and col - i + self.n - 1 < self.grid_size and row + i >= self.n - 1 and row + i < self.grid_size:\n",
    "                if sum([self.grid[col - i + x, row + i - x] for x in range(0, self.n)]) == self.n*player:\n",
    "                    self.finished = 1\n",
    "                    return 1\n",
    "        return 0\n",
    "\n",
    "    def move(self, col, player):\n",
    "        \n",
    "        self.turn_num += 1\n",
    "        \n",
    "        if self.finished == 1:\n",
    "            return 1, 50\n",
    "        sum_col = np.sum([abs(x) for x in self.grid[col]])\n",
    "        if sum_col == self.grid_size:\n",
    "            return -1, -1\n",
    "        self.grid[col, sum_col] = player\n",
    "        if self.check_win(col, sum_col, player) == 1:\n",
    "            return 1, 50\n",
    "        return 0, 0\n",
    "    \n",
    "    def turn(self):\n",
    "        \"\"\"\n",
    "        Returns which player's turn it is. First turn is player 1, second turn is player -1.\n",
    "        \"\"\"\n",
    "        if self.turn_num%2 == 0:\n",
    "            return 1\n",
    "        else:\n",
    "            return -1\n",
    "        \n",
    "    def next_possible_moves(self):\n",
    "        \"\"\"\n",
    "        Returns array of possible columns for a next move\n",
    "        \"\"\"\n",
    "        columns = []\n",
    "        \n",
    "        for i in xrange(0, self.grid_size):\n",
    "            if (0 in self.grid[i]):\n",
    "                columns.append(i)\n",
    "                \n",
    "        return columns\n",
    "    \n",
    "    def all_tokens_placed(self):\n",
    "        \"\"\"\n",
    "        Returns location of all tokens (column, row) that have been placed\n",
    "        \"\"\"\n",
    "        all_tokens = []\n",
    "        \n",
    "        for col in xrange(0, self.grid_size):\n",
    "            for row in xrange(0, self.grid_size): \n",
    "                if self.grid[col][row] != 0:\n",
    "                    all_tokens.append({\"location\": [col, row], \"player\": self.grid[col][row]})\n",
    "                    \n",
    "        return all_tokens\n",
    "    \n",
    "    def is_empty(self, col, row):\n",
    "        return self.grid[col][row] == 0\n",
    "    \n",
    "    def print_grid(self):\n",
    "        print(np.rot90(self.grid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def run_trial(agent, MIN_ITERATIONS, MIN_EPISODES, player):\n",
    "    \"\"\"\n",
    "    Runs the ConnectN Simulator for one player given an agent and number of iterations and episodes\n",
    "    \"\"\"\n",
    "    \n",
    "    rewards_by_iteration = []\n",
    "    rewards_by_episode = []\n",
    "    cumu_rewards_by_iteration = []\n",
    "    cumu_rewards_by_episode = []\n",
    "    \n",
    "    iteration = episode = 0\n",
    "    agent.reset()\n",
    "\n",
    "    while iteration < MIN_ITERATIONS or episode < MIN_EPISODES:\n",
    "        \n",
    "        task.reset()\n",
    "        board_state = task.grid\n",
    "        reward = None\n",
    "        cumulative_reward = 0\n",
    "\n",
    "        while iteration < MIN_ITERATIONS or episode < MIN_EPISODES:\n",
    "                        \n",
    "            action = agent.interact(reward, board_state, iteration)\n",
    "\n",
    "            if task.move(action, player)[1] == 50:\n",
    "                print \"Won!\"\n",
    "                break\n",
    "\n",
    "            return_val, reward = task.move(action, player)\n",
    "\n",
    "            if iteration < MIN_ITERATIONS:\n",
    "                print np.rot90(task.grid)\n",
    "\n",
    "                rewards_by_iteration.append(reward)\n",
    "                if cumu_rewards_by_iteration == []:\n",
    "                    cumu_rewards_by_iteration.append(reward)\n",
    "                else:\n",
    "                    cumu_rewards_by_iteration.append(cumu_rewards_by_iteration[-1] + reward)\n",
    "                \n",
    "            cumulative_reward += reward\n",
    "\n",
    "            iteration += 1\n",
    "\n",
    "        if episode < MIN_EPISODES:\n",
    "            rewards_by_episode.append(cumulative_reward)\n",
    "            if cumu_rewards_by_episode == []:\n",
    "                cumu_rewards_by_episode.append(cumulative_reward)\n",
    "            else:\n",
    "                cumu_rewards_by_episode.append(cumu_rewards_by_episode[-1] + cumulative_reward)\n",
    "        episode += 1\n",
    "        \n",
    "    return rewards_by_iteration, rewards_by_episode, cumu_rewards_by_iteration, cumu_rewards_by_episode"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tree Data Structure and MCTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class Node(object):\n",
    "    \"\"\"\n",
    "    Define a Tree Data Structure\n",
    "    \"\"\"\n",
    "    def __init__(self, state, parent, action_taken):\n",
    "        self.state = state\n",
    "        self.parent = parent\n",
    "        self.actions = []\n",
    "        self.action_taken = action_taken\n",
    "        self.children = []\n",
    "        self.total_reward = 0\n",
    "        self.total_visit_count = 0.000001\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class MCTS(object):\n",
    "    \"\"\"\n",
    "    Monte Carlo Tree Search \n",
    "    UCT algorithm from \"A Survey of Monte Carlo Tree Search Methods\n",
    "    \n",
    "    Node is Agent's move, next move is enemy\n",
    "    \"\"\"    \n",
    "    def __init__(self, max_iter, C):\n",
    "        self.max_iter = max_iter\n",
    "        self.C = C\n",
    "        \n",
    "    def reset(self):\n",
    "        self.__init__(self.max_iter, self.C)\n",
    "        \n",
    "    def full_check_win(self,board):\n",
    "        for col in xrange(0,board.grid_size):\n",
    "            for row in xrange(0,board.grid_size):\n",
    "                if board.check_win(col, row, 1) == 1:\n",
    "                    return True\n",
    "                if board.check_win(col, row, -1) == 1:\n",
    "                    return True\n",
    "        return False\n",
    "        \n",
    "    def uct_search(self,board):\n",
    "        iterator = 0\n",
    "        root = Node(board, None, None)\n",
    "        while iterator < self.max_iter:\n",
    "            c_node = self.tree_policy(root)\n",
    "            d = self.default_policy(c_node.state)\n",
    "            self.backup(c_node,d)\n",
    "            iterator = iterator + 1\n",
    "        return self.best_child(root,0)\n",
    "        \n",
    "    def tree_policy(self,node):\n",
    "        x = node\n",
    "        while self.full_check_win(x.state) == False and x.state.next_possible_moves() != []:\n",
    "            if list(set(x.state.next_possible_moves()) - set(x.actions)) != []:\n",
    "                return self.expand(x)\n",
    "            else: \n",
    "                x = x.children[self.best_child(x,self.C)]\n",
    "        return x\n",
    "    \n",
    "    def expand(self,node):\n",
    "        untried = list(set(node.state.next_possible_moves()) - set(node.actions))\n",
    "        if untried != []: \n",
    "            child = copy.deepcopy(node)\n",
    "            child.state.move(untried[0],1)\n",
    "            node.children.append(Node(child.state, node, untried[0]))\n",
    "            node.actions.append(untried[0])\n",
    "            return node.children[-1]\n",
    "        return \n",
    "\n",
    "    \n",
    "    def best_child(self,node,c):\n",
    "        child_vals = [((x.total_reward)/(x.total_visit_count) + c * np.sqrt(2*np.log(node.total_visit_count)/x.total_visit_count)) for x in node.children]\n",
    "        best_inx = argmax_breaking_ties_randomly(child_vals)  \n",
    "        best_c = node.children[best_inx]\n",
    "        #print(child_vals)\n",
    "        return best_c.action_taken\n",
    "        \n",
    "    def default_policy(self,board):\n",
    "        # assumes that agent is player 1\n",
    "        board2 = copy.deepcopy(board)\n",
    "        if self.full_check_win(board2) == True:\n",
    "            return 50\n",
    "        while True:\n",
    "            if board2.turn() == -1:\n",
    "                # imagined enemy\n",
    "                action2 = np.random.choice(board2.next_possible_moves())\n",
    "                board2.move(action2, -1)\n",
    "                if self.full_check_win(board2) == True:\n",
    "                    return -50\n",
    "                if board2.next_possible_moves() == []:\n",
    "                    return 0\n",
    "            # agent\n",
    "            if board2.turn() == 1:\n",
    "                action = np.random.choice(board2.next_possible_moves())\n",
    "                board2.move(action, 1)\n",
    "                if self.full_check_win(board2) == True:\n",
    "                    return 50\n",
    "                if board2.next_possible_moves() == []:\n",
    "                    return 0\n",
    "            \n",
    "    def backup(self,node,d):\n",
    "        v = node \n",
    "        while v != None:\n",
    "            v.total_visit_count = v.total_visit_count + 1\n",
    "            v.total_reward = v.total_reward + d\n",
    "            v = v.parent\n",
    "        return\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 1, 2, 3, 4]\n",
      "[[ 0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.]\n",
      " [-1. -1.  1.  0. -1.]\n",
      " [ 1. -1.  1.  0.  1.]]\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "Testing\n",
    "'''\n",
    "MCTSAgent = MCTS(1000,0.5)\n",
    "\n",
    "board = ConnectN(5,3)\n",
    "board.move(4,1)\n",
    "board.move(4,-1)\n",
    "board.move(2,1)\n",
    "board.move(1,-1)\n",
    "board.move(0,1)\n",
    "board.move(0,-1)\n",
    "board.move(2,1)\n",
    "board.move(1,-1)\n",
    "print(board.next_possible_moves())\n",
    "board.print_grid()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n"
     ]
    }
   ],
   "source": [
    "print MCTSAgent.uct_search(board)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
