{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from numpy.random import rand\n",
    "import math\n",
    "from random import randint\n",
    "import itertools\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import random\n",
    "from copy import deepcopy \n",
    "import copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class ConnectN:\n",
    "    \"\"\"\n",
    "    Connect N game simulator for two players, 1 and -1.\n",
    "    \n",
    "    Inputs:\n",
    "    Grid size- creates a grid size x grid size square board\n",
    "    N- number of tokens a player must connect to win the game\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, grid_size, n):\n",
    "        self.n = n\n",
    "        self.grid_size = grid_size\n",
    "        self.grid = np.zeros([grid_size,grid_size])\n",
    "        self.finished = 0\n",
    "        self.turn_num = 0\n",
    "        \n",
    "    def reset(self):\n",
    "        self.__init__(self.grid_size, self.n)\n",
    "\n",
    "    def check_win(self, col, row, player):\n",
    "        \"\"\"\n",
    "        Checks if given player has connected N tokens.\n",
    "        \"\"\"\n",
    "        for i in range(0, self.n):\n",
    "            if sum(self.grid[col, row - i:row - i + self.n]) == self.n*player:\n",
    "                self.finished = 1\n",
    "                return 1\n",
    "            if sum(self.grid[col - i: col - i + self.n, row]) == self.n*player:\n",
    "                self.finished = 1\n",
    "                return 1\n",
    "            if col - i >= 0 and col - i + self.n - 1 < self.grid_size and row - i >= 0 and row - i + self.n - 1 < self.grid_size:\n",
    "                if sum([self.grid[col - i + x, row - i + x] for x in range(0, self.n)]) == self.n*player:\n",
    "                    self.finished = 1\n",
    "                    return 1\n",
    "            if col - i >= 0 and col - i + self.n - 1 < self.grid_size and row + i >= self.n - 1 and row + i < self.grid_size:\n",
    "                if sum([self.grid[col - i + x, row + i - x] for x in range(0, self.n)]) == self.n*player:\n",
    "                    self.finished = 1\n",
    "                    return 1\n",
    "        return 0\n",
    "\n",
    "    def move(self, col, player):\n",
    "        \"\"\"\n",
    "        Given player and column to move in, modifies board and increments the turn counter.\n",
    "        \n",
    "        Returns a tuple, where first value is return message and second value is reward.\n",
    "        \"\"\"\n",
    "        self.turn_num += 1\n",
    "        \n",
    "        if self.finished == 1:\n",
    "            return 1, 50\n",
    "        sum_col = np.sum([abs(x) for x in self.grid[col]])\n",
    "        if sum_col == self.grid_size:\n",
    "            return -1, -1\n",
    "        self.grid[col, sum_col] = player\n",
    "        if self.check_win(col, sum_col, player) == 1:\n",
    "            return 1, 50\n",
    "        return 0, 0\n",
    "    \n",
    "    def simulate_move(self, col, player):\n",
    "        \"\"\"\n",
    "        Tests a move and returns if it is valid or not\n",
    "        \"\"\"\n",
    "        sum_col = np.sum([abs(x) for x in self.grid[col]])\n",
    "        if sum_col == self.grid_size:\n",
    "            return 1\n",
    "        else:\n",
    "            return 0\n",
    "        \n",
    "    def turn(self):\n",
    "        \"\"\"\n",
    "        Returns which player's turn it is. First turn is player 1, second turn is player -1.\n",
    "        \"\"\"\n",
    "        if self.turn_num%2 == 0:\n",
    "            return 1\n",
    "        else:\n",
    "            return -1\n",
    "        \n",
    "    def next_possible_moves(self):\n",
    "        \"\"\"\n",
    "        Returns array of possible columns for a next move\n",
    "        \"\"\"\n",
    "        columns = []\n",
    "        \n",
    "        for i in xrange(0, self.grid_size):\n",
    "            if (0 in self.grid[i]):\n",
    "                columns.append(i)\n",
    "                \n",
    "        return columns\n",
    "    \n",
    "    def all_tokens_placed(self):\n",
    "        \"\"\"\n",
    "        Returns location of all tokens (column, row) that have been placed\n",
    "        \"\"\"\n",
    "        all_tokens = []\n",
    "        \n",
    "        for col in xrange(0, self.grid_size):\n",
    "            for row in xrange(0, self.grid_size): \n",
    "                if self.grid[col][row] != 0:\n",
    "                    all_tokens.append({\"location\": [col, row], \"player\": self.grid[col][row]})\n",
    "                    \n",
    "        return all_tokens\n",
    "    \n",
    "    def is_empty(self, col, row):\n",
    "        \"\"\"\n",
    "        Returns if a given spot (column, row) is empty\n",
    "        \"\"\"\n",
    "        return self.grid[col][row] == 0\n",
    "    \n",
    "    def print_grid(self):\n",
    "        print(np.rot90(self.grid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def grid_to_key(grid):\n",
    "    \"\"\"\n",
    "    Converts ConnectN grid into string for dict indexing\n",
    "    \"\"\"\n",
    "\n",
    "    key = \"\"\n",
    "\n",
    "    for row in np.rot90(grid):\n",
    "        for column in row:\n",
    "            key += str(int(column))\n",
    "\n",
    "    return key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class ConnectDict(dict):\n",
    "    \"\"\"\n",
    "    Creates a Custom Dict that inherits from Python's native dict.\n",
    "    Takes in a number of states.\n",
    "    Adds keys to dict each time lookup is necessary to avoid full dict initialization.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, num_states, *arg, **kw):\n",
    "        self.num_states = num_states\n",
    "        super(ConnectDict, self).__init__(*arg, **kw)\n",
    "        \n",
    "    def __getitem__(self, key):\n",
    "        \n",
    "        if key not in self.__dict__:\n",
    "            dict.__setitem__(self, key, np.zeros(self.num_states))\n",
    "        return dict.__getitem__(self, key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class TD_Learner(object):\n",
    "    \"\"\"\n",
    "    Base class for Temporal Difference Learners, like Sarsa and Q learning.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, task, value_table=None, epsilon=.1, discount_factor=.9, learning_rate=.5, player=1, trace_size=.1):\n",
    "        \n",
    "        self.num_states = task.grid_size\n",
    "        self.num_actions = task.grid_size\n",
    "        self.epsilon = epsilon\n",
    "        self.discount_factor = discount_factor\n",
    "        self.learning_rate = learning_rate\n",
    "        \n",
    "        if value_table == None:\n",
    "            self.value_table = ConnectDict(self.num_states)\n",
    "        else:\n",
    "            self.value_table = value_table\n",
    "            \n",
    "        self.e = ConnectDict(self.num_states)\n",
    "        self.player = player\n",
    "        self.trace_size = trace_size\n",
    "        self.last_board_state = None\n",
    "        self.last_action = None\n",
    "\n",
    "#     def reset(self):\n",
    "#         self.last_board_state = None\n",
    "#         self.last_action = None\n",
    "    \n",
    "    def softmax(self, next_board_state):\n",
    "        \"\"\"\n",
    "        Implementation of Softmax Policy, which weights towards better actions rather\n",
    "        than sampling uniformly across all possible actions (epsilon-greedy)\n",
    "        \"\"\"\n",
    "        \n",
    "        def weighted_pick(weights,n_picks):\n",
    "            t = np.cumsum(weights)\n",
    "            s = sum(weights)\n",
    "            return np.searchsorted(t,rand(n_picks)*s)\n",
    "\n",
    "        tau = .5\n",
    "        num = math.e**(self.value_table[grid_to_key(next_board_state.grid)]/tau)\n",
    "        probs = num/sum(num)\n",
    "        best_action = weighted_pick(probs, 1)\n",
    "\n",
    "        return best_action[0]\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def run_trial(agent, MIN_ITERATIONS, MIN_EPISODES, player):\n",
    "    \"\"\"\n",
    "    Runs the ConnectN Simulator for one player given an agent and number of iterations and episodes\n",
    "    \"\"\"\n",
    "    \n",
    "    rewards_by_iteration = []\n",
    "    rewards_by_episode = []\n",
    "    cumu_rewards_by_iteration = []\n",
    "    cumu_rewards_by_episode = []\n",
    "    \n",
    "    iteration = episode = 0\n",
    "    #agent.reset()\n",
    "    \n",
    "    new_value_table = None\n",
    "\n",
    "    while iteration < MIN_ITERATIONS or episode < MIN_EPISODES:\n",
    "        \n",
    "        task.reset()\n",
    "        board_state = task\n",
    "        reward = None\n",
    "        cumulative_reward = 0\n",
    "\n",
    "        while iteration < MIN_ITERATIONS or episode < MIN_EPISODES:\n",
    "                        \n",
    "            action = agent.interact(reward, board_state)\n",
    "\n",
    "            if task.move(action, player)[1] == 50:\n",
    "                print \"Won!\"\n",
    "                break\n",
    "\n",
    "            return_val, reward = task.move(action, player)\n",
    "\n",
    "            if iteration < MIN_ITERATIONS:\n",
    "                #print np.rot90(task.grid)\n",
    "\n",
    "                rewards_by_iteration.append(reward)\n",
    "                if cumu_rewards_by_iteration == []:\n",
    "                    cumu_rewards_by_iteration.append(reward)\n",
    "                else:\n",
    "                    cumu_rewards_by_iteration.append(cumu_rewards_by_iteration[-1] + reward)\n",
    "                \n",
    "            cumulative_reward += reward\n",
    "\n",
    "            iteration += 1\n",
    "\n",
    "        if episode < MIN_EPISODES:\n",
    "            rewards_by_episode.append(cumulative_reward)\n",
    "            if cumu_rewards_by_episode == []:\n",
    "                cumu_rewards_by_episode.append(cumulative_reward)\n",
    "            else:\n",
    "                cumu_rewards_by_episode.append(cumu_rewards_by_episode[-1] + cumulative_reward)\n",
    "        episode += 1\n",
    "        \n",
    "    return rewards_by_iteration, rewards_by_episode, cumu_rewards_by_iteration, cumu_rewards_by_episode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class Q_Learner(TD_Learner):\n",
    "    \"\"\"\n",
    "    Implementation of Q Learning, inheriting from TD Learner base class. \n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, task, value_table, epsilon=.1, discount_factor=.9, learning_rate=.5, player=1, trace_size=.1):   \n",
    "        TD_Learner.__init__(self, task, value_table, epsilon, discount_factor, learning_rate, player, trace_size) \n",
    "        \n",
    "\n",
    "    def interact(self, reward, next_board_state):\n",
    "        if reward is None:\n",
    "            next_action = self.softmax(next_board_state)\n",
    "\n",
    "            self.last_board_state = next_board_state.grid\n",
    "            self.last_action = next_action\n",
    "            return self.last_action\n",
    "                \n",
    "        if reward == 50:\n",
    "            delta = delta = reward - self.value_table[grid_to_key(self.last_board_state)][self.last_action]\n",
    "            self.value_table[grid_to_key(self.last_board_state)][self.last_action] += self.learning_rate * delta\n",
    "            return self.last_action\n",
    "        \n",
    "        \"\"\"\n",
    "        VDBE-Softmax policy. If draw < epsilon, perform Softmax. Else do best action.\n",
    "        \"\"\"\n",
    "        draw = np.random.uniform(0,1,1)\n",
    "\n",
    "        if draw < self.epsilon:\n",
    "            next_action = self.softmax(next_board_state)\n",
    "        else:\n",
    "            next_action = np.argmax(self.value_table[grid_to_key(next_board_state.grid)])\n",
    "\n",
    "        # Update value function.\n",
    "        delta = reward + self.discount_factor * np.amax(self.value_table[grid_to_key(next_board_state.grid)]) - self.value_table[grid_to_key(self.last_board_state)][self.last_action]\n",
    "        self.value_table[grid_to_key(self.last_board_state)][self.last_action] += self.learning_rate * delta\n",
    "        \n",
    "        # Update eligibility traces (Watson's Q(lambda))\n",
    "        self.e[grid_to_key(self.last_board_state)][self.last_action] += 1\n",
    "\n",
    "        # Eligibility traces\n",
    "        # Note that here we do not implement classic eligibility traces, which iterate over all state, action pairs\n",
    "        # Instead we consider all next possible board states and update those (for easier computation)\n",
    "        next_possible_moves = next_board_state.next_possible_moves()\n",
    "        next_possible_boards = []\n",
    "        \n",
    "        for i in next_possible_moves:\n",
    "            temp_board = deepcopy(next_board_state)\n",
    "            temp_board.move(next_action, self.player)\n",
    "            next_possible_boards.append(temp_board)\n",
    "            \n",
    "        for board in next_possible_boards:\n",
    "            valid_actions = board.next_possible_moves()\n",
    "            for action in valid_actions:\n",
    "                self.value_table[grid_to_key(board.grid)][action] += self.learning_rate * delta \\\n",
    "                                                                    * self.e[grid_to_key(board.grid)][action]\n",
    "                if self.last_action == action:\n",
    "                    self.e[grid_to_key(board.grid)][action] = self.discount_factor * self.trace_size \\\n",
    "                                                                    * self.e[grid_to_key(board.grid)][action]\n",
    "                else:\n",
    "                    self.e[grid_to_key(board.grid)][action] = 0\n",
    "                    \n",
    "        self.last_board_state = next_board_state.grid\n",
    "        self.last_action = next_action\n",
    "\n",
    "        if next_board_state.simulate_move(self.last_action, self.player) == 1:\n",
    "            self.last_action = self.softmax(next_board_state)\n",
    "            \n",
    "        return self.last_action\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "task = ConnectN(7, 4)\n",
    "agent = Q_Learner(task, None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Won!\n",
      "Won!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "([0, 0, 50, 0, 0, 0, 50, 0, 0, 50],\n",
       " [50],\n",
       " [0, 0, 50, 50, 50, 50, 100, 100, 100, 150],\n",
       " [50])"
      ]
     },
     "execution_count": 284,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "run_trial(agent, 10, 1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def play_game(board, p1, p2, q=False):\n",
    "    \"\"\"\n",
    "    Runs Connect 4 game given simulator object and two agents (players)\n",
    "    \"\"\"\n",
    "    reward = None\n",
    "    \n",
    "    if q == True:\n",
    "        while True:\n",
    "            print(\"p1\")\n",
    "            p1move = p1.interact(reward, board)\n",
    "            print(p1move)\n",
    "            if (p1move is None):\n",
    "                board.print_grid()\n",
    "                print(\"error player 1 a\")\n",
    "                return -1\n",
    "            p1result, reward = board.move(p1move, 1)\n",
    "            print p1result\n",
    "            if (p1result == 1):\n",
    "                print(\"player 1\")\n",
    "                board.print_grid()\n",
    "                return 1\n",
    "            elif (p1result == -1):\n",
    "                board.print_grid()\n",
    "                print(\"error player 1 b\")\n",
    "                return -1\n",
    "            print(\"p2\")\n",
    "            p2move = p2.calc_next_move()\n",
    "            print(p2move)\n",
    "            if (p2move is None):\n",
    "                board.print_grid()\n",
    "                print(\"error player 2\")\n",
    "                return -1\n",
    "            p2result = board.move(p2move, -1)\n",
    "            print p2result\n",
    "            if (p2result[0] == 1):\n",
    "                print(\"player 2\")\n",
    "                board.print_grid()\n",
    "                return 1\n",
    "            elif (p2result[0] == -1):\n",
    "                board.print_grid()\n",
    "                print(\"error player 2\")\n",
    "                return -1\n",
    "    \n",
    "    else:\n",
    "        while True:\n",
    "            print(\"p1\")\n",
    "            p1move = p1.calc_next_move()\n",
    "            print(p1move)\n",
    "            if (p1move is None):\n",
    "                board.print_grid()\n",
    "                print(\"error\")\n",
    "                return -1\n",
    "            p1result = board.move(p1move, 1)\n",
    "            print p1result\n",
    "            if (p1result[0] == 1):\n",
    "                print(\"player 1\")\n",
    "                board.print_grid()\n",
    "                return 1\n",
    "            elif (p1result[0] == -1):\n",
    "                board.print_grid()\n",
    "                print(\"error\")\n",
    "                return -1\n",
    "            print(\"p2\")\n",
    "            p2move = p2.calc_next_move()\n",
    "            print(p2move)\n",
    "            if (p2move is None):\n",
    "                board.print_grid()\n",
    "                print(\"error\")\n",
    "                return -1\n",
    "            p2result = board.move(p2move, -1)\n",
    "            print p2result\n",
    "            if (p2result[0] == 1):\n",
    "                print(\"player 2\")\n",
    "                board.print_grid()\n",
    "                return 1\n",
    "            elif (p2result[0] == -1):\n",
    "                board.print_grid()\n",
    "                print(\"error\")\n",
    "                return -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Random_Learner(object):\n",
    "    \"\"\"\n",
    "    Implementation of Connect 4 agent that takes random moves at each action step\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, board):\n",
    "        self.board = board\n",
    "\n",
    "    def calc_next_move(self):\n",
    "        moves = self.board.next_possible_moves()\n",
    "        return moves[random.randint(0, len(moves) - 1)]\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def play_game_no_output(board, p1, p2, q=False):\n",
    "    \"\"\"\n",
    "    Runs Connect 4 game given simulator object and two agents (players)\n",
    "    \"\"\"\n",
    "    reward = None\n",
    "    \n",
    "    if q == True:\n",
    "        while True:\n",
    "            p1move = p1.interact(reward, board)\n",
    "            if (p1move is None):\n",
    "                return -1\n",
    "            p1result, reward = board.move(p1move, 1)\n",
    "            if (p1result == 1):\n",
    "                p1.interact(reward, board)\n",
    "                return 1\n",
    "            elif (p1result == -1):\n",
    "                return -1\n",
    "            p2move = p2.calc_next_move()\n",
    "            if (p2move is None):\n",
    "                return -1\n",
    "            p2result = board.move(p2move, -1)\n",
    "            if (p2result[0] == 1):\n",
    "                return 2\n",
    "            elif (p2result[0] == -1):\n",
    "                return -1\n",
    "    \n",
    "    else:\n",
    "        while True:\n",
    "            print(\"p1\")\n",
    "            p1move = p1.calc_next_move()\n",
    "            print(p1move)\n",
    "            if (p1move is None):\n",
    "                board.print_grid()\n",
    "                print(\"error\")\n",
    "                return -1\n",
    "            p1result = board.move(p1move, 1)\n",
    "            print p1result\n",
    "            if (p1result[0] == 1):\n",
    "                print(\"player 1\")\n",
    "                board.print_grid()\n",
    "                return 1\n",
    "            elif (p1result[0] == -1):\n",
    "                board.print_grid()\n",
    "                print(\"error\")\n",
    "                return -1\n",
    "            print(\"p2\")\n",
    "            p2move = p2.calc_next_move()\n",
    "            print(p2move)\n",
    "            if (p2move is None):\n",
    "                board.print_grid()\n",
    "                print(\"error\")\n",
    "                return -1\n",
    "            p2result = board.move(p2move, -1)\n",
    "            print p2result\n",
    "            if (p2result[0] == 1):\n",
    "                print(\"player 2\")\n",
    "                board.print_grid()\n",
    "                return 1\n",
    "            elif (p2result[0] == -1):\n",
    "                board.print_grid()\n",
    "                print(\"error\")\n",
    "                return -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 318,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def train_Q_learner(num_trials = 1000, k=2, n=4, grid_size = 7):\n",
    "    \"\"\"\n",
    "    Trains the Q Learner against Minimax Depth k\n",
    "    \n",
    "    Inputs:\n",
    "    Number of games to play\n",
    "    On grid_size x\n",
    "    N tokens to connect\n",
    "    \n",
    "    Outputs:\n",
    "    Q Learner value table after training\n",
    "    \"\"\"\n",
    "    depth = k\n",
    "    N = n\n",
    "    grid_size = grid_size\n",
    "    x = ConnectN(grid_size, N)\n",
    "    \n",
    "    p1 = Q_Learner(x, value_table=None)\n",
    "    #p2 = Minimax_Learner(x, depth, N, 1, \"minimax\")  \n",
    "    p2 = Random_Learner(x)\n",
    "    play_game_no_output(x, p1, p2, True)\n",
    "    \n",
    "    for game in xrange(1, num_trials):\n",
    "                \n",
    "        x = ConnectN(grid_size, N)\n",
    "        #print(p1.value_table)\n",
    "        p1 = Q_Learner(x, value_table=p1.value_table)\n",
    "#       p2 = Minimax_Learner(x, 2, 4, 1, \"minimax\")  \n",
    "        p2 = Random_Learner(x)\n",
    "        play_game_no_output(x, p1, p2, True)\n",
    "        \n",
    "        if game % 10 == 0:\n",
    "            print len(p1.value_table)\n",
    "        \n",
    "        if game == num_trials - 1:\n",
    "            return p1.value_table\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 320,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'0000000000000000000000000000100000010000-10100-10-10': array([ 0.,  0.,  0.,  0.,  0.,  0.,  0.]), '00000000000000100000010000001000000-1-1000001-10001-1': array([ 0.,  0.,  0.,  0.,  0.,  0.,  0.]), '00000000000000000000000000000000000000000000100-10': array([ 0.,  0.,  0.,  0.,  0.,  0.,  0.]), '00000000000000000000000000000000000000000010000-10': array([ 0.,  0.,  0.,  0.,  0.,  0.,  0.]), '000000000000000000000000000000000-1010000-1-1101001-1': array([ 0.,  0.,  0.,  0.,  0.,  0.,  0.]), '000000010000001000000-10000001000000-100-10001001-100': array([ 0.,  0.,  0.,  0.,  0.,  0.,  0.]), '00000000000000000000010000001000000-10000001-10001-1': array([ 0.,  0.,  0.,  0.,  0.,  0.,  0.]), '-100000010000001000000-10000001000000-100-11001001-1-10': array([ 0.,  0.,  0.,  0.,  0.,  0.,  0.]), '00000000000000000000010000001000000-1-1000001-10001-1': array([ 0.,  0.,  0.,  0.,  0.,  0.,  0.]), '00000000000000000000010000001000000100-10-101-1010-10': array([ 25.,   0.,   0.,   0.,   0.,   0.,   0.]), '-100000010000001000000-100-10001001100-100-11-1-11-111-1-11': array([ 0.,  0.,  0.,  0.,  0.,  0.,  0.]), '000000000000000000000100000010000001-1-100001-11000-1': array([ 25.,   0.,   0.,   0.,   0.,   0.,   0.]), '0000000000000000000000000000000000010-1-10-1010-1-1111': array([ 0.,  0.,  0.,  0.,  0.,  0.,  0.]), '0000000000000000000000000000000000000000001-110000': array([ 0.,  0.,  0.,  0.,  0.,  0.,  0.]), '00000000000000000000000000001000000100000011-1-10-1-1': array([ 0.,  0.,  0.,  0.,  0.,  0.,  0.]), '0000000000000000000000000000000000010-1-100010-1-1111': array([ 0.,  0.,  0.,  0.,  0.,  0.,  0.]), '0000000000000000000001000000100000010000-101-11-10-10': array([ 25.,   0.,   0.,   0.,   0.,   0.,   0.]), '00000001000000100000010000001000000-1-1000001-10-101-1': array([ 25.,   0.,   0.,   0.,   0.,   0.,   0.]), '0000000000000000000000000000100000010000-101-1010-10': array([ 0.,  0.,  0.,  0.,  0.,  0.,  0.]), '00000000000000000000000000000000000100000010000-10': array([ 0.,  0.,  0.,  0.,  0.,  0.,  0.]), '000000000000000000000000000000000000000000101000-1': array([ 0.,  0.,  0.,  0.,  0.,  0.,  0.]), '00000000000000000000000000001000000100000011-100-1-1': array([ 0.,  0.,  0.,  0.,  0.,  0.,  0.]), '0000000000000000000000000000100000010-100-101010-1-10': array([ 0.,  0.,  0.,  0.,  0.,  0.,  0.]), '0000000000000000000000000000000000000000001-11000-1': array([ 0.,  0.,  0.,  0.,  0.,  0.,  0.]), '0000000000000000000000000000000000010000001-1010-10': array([ 0.,  0.,  0.,  0.,  0.,  0.,  0.]), '00000000000000000000000000000000000100000011000-1-1': array([ 0.,  0.,  0.,  0.,  0.,  0.,  0.]), '0000000000000000000000000000000000010000001-11-10-10': array([ 0.,  0.,  0.,  0.,  0.,  0.,  0.]), '0000000000000000000000000000000000010-1000010-1-1101': array([ 0.,  0.,  0.,  0.,  0.,  0.,  0.]), '0000000000000000000000000000000000010000-1010000-10': array([ 0.,  0.,  0.,  0.,  0.,  0.,  0.]), '-100000010000001000000-100-10001001100-100-11001-101-1-10': array([ 0.,  0.,  0.,  0.,  0.,  0.,  0.]), '0000000000000000000000000000000000000-1000010-10101': array([ 0.,  0.,  0.,  0.,  0.,  0.,  0.]), '000000000000000000000000000000000000000000010000-1': array([ 0.,  0.,  0.,  0.,  0.,  0.,  0.]), '0000000000000000000000000000000000000000000-110000': array([ 0.,  0.,  0.,  0.,  0.,  0.,  0.]), '0000000000000000000000000000000000010-1-100010-1-1101': array([ 0.,  0.,  0.,  0.,  0.,  0.,  0.]), '0000000000000000000000000000000000000000-1010100-10': array([ 0.,  0.,  0.,  0.,  0.,  0.,  0.]), '000000000000000000000100000010000-1010000-1-11010-11-1': array([ 25.,   0.,   0.,   0.,   0.,   0.,   0.]), '0000000000000000000000000000000000000000-10101001-1': array([ 0.,  0.,  0.,  0.,  0.,  0.,  0.]), '0000000000000000000000000000000000000000001-1010-10': array([ 0.,  0.,  0.,  0.,  0.,  0.,  0.]), '0000000000000000000000000000100000010-1-10-1010-1-1111': array([ 0.,  0.,  0.,  0.,  0.,  0.,  0.]), '00000000000000000000000000000000000-10000001001-100': array([ 0.,  0.,  0.,  0.,  0.,  0.,  0.]), '00000000000000000000000000001000000-1000000100001-1': array([ 0.,  0.,  0.,  0.,  0.,  0.,  0.]), '0000000000000000000000000000000000000000000001-100': array([ 0.,  0.,  0.,  0.,  0.,  0.,  0.]), '000000000000000000000000000000000-1010000-10101001-1': array([ 0.,  0.,  0.,  0.,  0.,  0.,  0.]), '00000000000000000000010000001000000100000011-1-10-1-1': array([ 25.,   0.,   0.,   0.,   0.,   0.,   0.]), '00000000000000000000000000000000000000000000-10101': array([ 0.,  0.,  0.,  0.,  0.,  0.,  0.]), '0000000000000000000000000000100000010000-101-11-10-10': array([ 0.,  0.,  0.,  0.,  0.,  0.,  0.]), '0000000000000000000000000000000000000000001-101000': array([ 0.,  0.,  0.,  0.,  0.,  0.,  0.]), '-100000010000001000000-10000001000000-100-10001001-100': array([ 0.,  0.,  0.,  0.,  0.,  0.,  0.]), '0000000000000000000000000000000000000000000000000': array([ 0.,  0.,  0.,  0.,  0.,  0.,  0.]), '000000000000000000000000000000000000000000100001-1': array([ 0.,  0.,  0.,  0.,  0.,  0.,  0.]), '000000000000000000000000000000000000000000001000-1': array([ 0.,  0.,  0.,  0.,  0.,  0.,  0.]), '00000000000000000000000000000000000000000011000-1-1': array([ 0.,  0.,  0.,  0.,  0.,  0.,  0.]), '-100000010000001000000-100-100010-11100-101-11-1-11-111-1-11': array([ 0.,  0.,  0.,  0.,  0.,  0.,  0.]), '0000000000000000000000000000000000010-100-1010100-10': array([ 0.,  0.,  0.,  0.,  0.,  0.,  0.]), '0000000000000000000000000000000000000000001-1100-10': array([ 0.,  0.,  0.,  0.,  0.,  0.,  0.]), '0000000000000000000000000000100000010000-1010000-10': array([ 0.,  0.,  0.,  0.,  0.,  0.,  0.]), '000000000000000000000000000000000001-1000001-11000-1': array([ 0.,  0.,  0.,  0.,  0.,  0.,  0.]), '00000000000000100000010000001000000-1-1000001-10-101-1': array([ 0.,  0.,  0.,  0.,  0.,  0.,  0.]), '00000000000000000000000000000000000100000011-100-1-1': array([ 0.,  0.,  0.,  0.,  0.,  0.,  0.]), '00000000000000000000000000000000000000000000-10001': array([ 0.,  0.,  0.,  0.,  0.,  0.,  0.]), '0000000000000000000000000000000000000000000-101000': array([ 0.,  0.,  0.,  0.,  0.,  0.,  0.]), '00000000000000000000000000001000000-10000001001-100': array([ 0.,  0.,  0.,  0.,  0.,  0.,  0.]), '0000000000000000000000000000000000000000-10100001-1': array([ 0.,  0.,  0.,  0.,  0.,  0.,  0.]), '0000000000000000000000000000000000010000-1010100-10': array([ 0.,  0.,  0.,  0.,  0.,  0.,  0.]), '0000000000000000000000000000000000010000001-11000-1': array([ 0.,  0.,  0.,  0.,  0.,  0.,  0.]), '000000000000000000000-10000001000000-10000001001-100': array([ 0.,  0.,  0.,  0.,  0.,  0.,  0.]), '-100000010000001000000-100-10001001100-100-11-101-111-1-10': array([ 0.,  0.,  0.,  0.,  0.,  0.,  0.]), '0000000000000000000000000000000000010000001-1100-10': array([ 0.,  0.,  0.,  0.,  0.,  0.,  0.]), '0000000000000000000000000000100000010000001-11-10-10': array([ 0.,  0.,  0.,  0.,  0.,  0.,  0.]), '0000000000000000000001000000100000010-100-101010-1-10': array([ 25.,   0.,   0.,   0.,   0.,   0.,   0.]), '000000000000000000000000000010000001-1000001-11000-1': array([ 0.,  0.,  0.,  0.,  0.,  0.,  0.]), '0000000000000000000000000000100000010-100-1010100-10': array([ 0.,  0.,  0.,  0.,  0.,  0.,  0.]), '00000000000000000000000000001000000-10000001-10001-1': array([ 0.,  0.,  0.,  0.,  0.,  0.,  0.]), '-100000010000001000000-100-10001001000-100-11001001-1-10': array([ 0.,  0.,  0.,  0.,  0.,  0.,  0.]), '000000000000000000000000000000000000000000110000-1': array([ 0.,  0.,  0.,  0.,  0.,  0.,  0.]), '0000000000000000000000000000000000000000001001-100': array([ 0.,  0.,  0.,  0.,  0.,  0.,  0.]), '000000000000000000000000000010000001-1-100001-11000-1': array([ 0.,  0.,  0.,  0.,  0.,  0.,  0.]), '0000000000000000000000000000000000010000-101-1010-10': array([ 0.,  0.,  0.,  0.,  0.,  0.,  0.]), '0000000000000000000000000000100000010000-10101-10-10': array([ 0.,  0.,  0.,  0.,  0.,  0.,  0.]), '0000000000000000000000000000000000000-1000000-10101': array([ 0.,  0.,  0.,  0.,  0.,  0.,  0.]), '000000000000000000000000000000000000000000000001-1': array([ 0.,  0.,  0.,  0.,  0.,  0.,  0.]), '000000000000000000000000000000000-1000000-10101001-1': array([ 0.,  0.,  0.,  0.,  0.,  0.,  0.]), '00000000000000000000000000000000000-1000000100001-1': array([ 0.,  0.,  0.,  0.,  0.,  0.,  0.]), '000000000000001000000-10000001000000-100-10001001-100': array([ 0.,  0.,  0.,  0.,  0.,  0.,  0.]), '000000000000000000000000000010000-1010000-1-1101001-1': array([ 0.,  0.,  0.,  0.,  0.,  0.,  0.]), '0000000000000000000000000000100000010000001-11-10-1-1': array([ 0.,  0.,  0.,  0.,  0.,  0.,  0.]), '000000000000000000000000000010000-1010000-1-11010-11-1': array([ 0.,  0.,  0.,  0.,  0.,  0.,  0.]), '0000000000000000000000000000000000000-1000010-1-1101': array([ 0.,  0.,  0.,  0.,  0.,  0.,  0.]), '0000000000000000000001000000100000010000001-11-10-1-1': array([ 25.,   0.,   0.,   0.,   0.,   0.,   0.]), '000000000000001000000-10000001000000-10000001001-100': array([ 0.,  0.,  0.,  0.,  0.,  0.,  0.]), '00000000000000000000000000000000000000000010100-10': array([ 0.,  0.,  0.,  0.,  0.,  0.,  0.]), '00000000000000000000000000001000000100-10-101-1010-10': array([ 0.,  0.,  0.,  0.,  0.,  0.,  0.])}\n"
     ]
    }
   ],
   "source": [
    "print train_Q_learner(num_trials=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Minimax_Learner(object):\n",
    "    \"\"\"\n",
    "    Implementation of AI algorithm Minimax with static evaluator \n",
    "    \n",
    "    Inputs:\n",
    "    Connect N board\n",
    "    Depth- Minimax Learner will build tree of next possible moves to that depth\n",
    "    N- number of tokens that need to be connected for a player to win\n",
    "    Player- player number, either 1 or -1\n",
    "    Algorithm- either \"minimax\" or \"ab\" for alpha beta pruned minimax\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, board, depth, n, player, alg):\n",
    "        self.board = board\n",
    "        self.depth = depth\n",
    "        self.num_states = board.grid_size\n",
    "        self.player = player\n",
    "        self.n = n\n",
    "        self.alg = alg\n",
    "        \n",
    "        \n",
    "    \"\"\"\n",
    "    Following streak functions check if player has token streak in the four possible win directions\n",
    "    \"\"\"\n",
    "    def streakVertical(self, board, col, row, player):\n",
    "        if row > len(board[col]) - self.n:\n",
    "            return 0\n",
    "        for i in range(0,self.n):\n",
    "            if board[col][row + i] == -1*player:\n",
    "                return 0\n",
    "            if board[col][row + i] == 0:\n",
    "                return i\n",
    "        return self.n\n",
    "\n",
    "    def streakHorizontal(self, board, col, row, player):\n",
    "        if col > len(board) - self.n:\n",
    "            return 0\n",
    "        for i in range(0,self.n):\n",
    "            if board[col + i][row] == -1*player:\n",
    "                return 0\n",
    "            if board[col + i][row] == 0:\n",
    "                return i\n",
    "        return self.n\n",
    "    \n",
    "    def streakDiagonalUp(self, board, col, row, player):\n",
    "        if row > len(board[col]) - self.n or col > len(board) - self.n:\n",
    "            return 0\n",
    "        for i in range(0,self.n):\n",
    "            if board[col + i][row + i] == -1*player:\n",
    "                return 0\n",
    "            if board[col + i][row + i] == 0:\n",
    "                return i\n",
    "        return self.n\n",
    "    \n",
    "    def streakDiagonalDown(self, board, col, row, player):\n",
    "        if row < self.n or col > len(board) - self.n:\n",
    "            return 0\n",
    "        for i in range(0,self.n):\n",
    "            if board[col + i][row - i] == -1*player:\n",
    "                return 0\n",
    "            if board[col + i][row - i] == 0:\n",
    "                return i\n",
    "        return self.n\n",
    "\n",
    "    def value(self, board):\n",
    "        \"\"\"\n",
    "        Calculates value of board states\n",
    "        \"\"\"\n",
    "        val = 0\n",
    "        conversion = [int(math.pow(2, i))/2 for i in range(0, self.n+1)]\n",
    "        conversion[self.n] = 20000000\n",
    "        conversion_other = [int(math.pow(2, i))/4 for i in range(0, self.n+1)]\n",
    "        conversion_other[self.n] = 1000000\n",
    "        for i in range(0, len(board)):\n",
    "            for j in range(0, len(board[0])):\n",
    "                temp = self.streakVertical(board, i, j, self.player)\n",
    "                if temp == self.n:\n",
    "                    return conversion[temp]\n",
    "                val += conversion[temp]\n",
    "                temp = self.streakHorizontal(board, i, j, self.player)\n",
    "\n",
    "                if temp == self.n:\n",
    "                    return conversion[temp]\n",
    "                val += conversion[temp]                \n",
    "                temp = self.streakDiagonalUp(board, i, j, self.player)\n",
    "                if temp == self.n:\n",
    "                    return conversion[temp]\n",
    "                val += conversion[temp]\n",
    "                \n",
    "                temp = self.streakDiagonalDown(board, i, j, self.player)\n",
    "                if temp == self.n:\n",
    "                    return conversion[temp]\n",
    "                val += conversion[temp]\n",
    "                \n",
    "                \n",
    "                temp = self.streakVertical(board, i, j, -1*self.player)\n",
    "                if temp == self.n:\n",
    "                    return -1*conversion_other[temp]\n",
    "                val -= conversion[temp]\n",
    "\n",
    "                temp = self.streakHorizontal(board, i, j, -1*self.player)\n",
    "                if temp == self.n:\n",
    "                    return -1*conversion_other[temp]\n",
    "                val -= conversion[temp]\n",
    "                temp = self.streakDiagonalUp(board, i, j, -1*self.player)\n",
    "                if temp == self.n:\n",
    "                    return -1*conversion_other[temp]\n",
    "                val -= conversion[temp]\n",
    "                temp = self.streakDiagonalDown(board, i, j, -1*self.player)\n",
    "                if temp == self.n:\n",
    "                    return -1*conversion_other[temp]\n",
    "                val -= conversion[temp]\n",
    "\n",
    "        return val\n",
    "        \n",
    "    def create_tree(self, node, depth, player, move):\n",
    "        \"\"\"\n",
    "        Creates tree of next possible moves\n",
    "        \n",
    "        Each node is a dict of node value, children, the board state, which player's turn it would be, and move\n",
    "        \"\"\"\n",
    "        if depth == 0:\n",
    "            return None\n",
    "        \n",
    "        else:\n",
    "            tree = {\"value\": 0, \"children\": [], \"board\": node, \"player\": player, \"move\": move}\n",
    "\n",
    "            next_moves = node.next_possible_moves()\n",
    "\n",
    "            for move in next_moves:\n",
    "                board_copy = copy.deepcopy(node)\n",
    "                board_copy.move(move, player)\n",
    "                new_child = self.create_tree(board_copy, depth-1, -1*player, move)\n",
    "                \n",
    "                if new_child != None:\n",
    "                    tree[\"children\"].append(new_child)\n",
    "\n",
    "            return tree\n",
    "\n",
    "    def children(self, node):\n",
    "        \"\"\" \n",
    "        returns children of a node\n",
    "        \"\"\"\n",
    "        return node[\"children\"]\n",
    "   \n",
    "    def leaf(self, node):\n",
    "        \"\"\"\n",
    "        returns if current node is a leaf (i.e. no children)\n",
    "        \"\"\"\n",
    "        return len(self.children(node)) == 0\n",
    "        \n",
    "    def max_node(self, node):\n",
    "        \"\"\"\n",
    "        returns true if node is a max node\n",
    "        \"\"\"\n",
    "        return node[\"player\"] == self.player\n",
    "        \n",
    "    def evaluate(self, node):\n",
    "        \"\"\"\n",
    "        Static evaluator function to return a value between Loss and Win for intermediate game\n",
    "        positions, larger if the position is better for the current player.\n",
    "        If depth limit of the search is exceeded, is applied to remaining nodes as if\n",
    "        they were leaves. \n",
    "        \n",
    "        We calculate the rating by checking each token already placed, and \n",
    "        checking how many possible ways to connect N there are\n",
    "        \"\"\"\n",
    "        node[\"value\"] = self.value(node[\"board\"].grid)\n",
    "        return node[\"value\"]       \n",
    "\n",
    "    def minimax(self, node, depth):\n",
    "        \"\"\" \n",
    "        Recursive implementation of Minimax algorithm using pseudocode from: \n",
    "        https://www.cs.cornell.edu/courses/cs312/2002sp/lectures/rec21.htm\n",
    "        \"\"\"\n",
    "        if self.leaf(node) or depth == 0:\n",
    "            return self.evaluate(node)\n",
    "        \n",
    "        if self.max_node(node):\n",
    "            # L = -infinity\n",
    "            current_node_value = -1000000000\n",
    "            for child in self.children(node):\n",
    "                next_node_value = self.minimax(child, depth-1)\n",
    "                if current_node_value < next_node_value:\n",
    "                    current_node_value = next_node_value\n",
    "            node[\"value\"] = current_node_value\n",
    "            return current_node_value\n",
    "        \n",
    "        if not self.max_node(node):\n",
    "            # W = +infinity\n",
    "            current_node_value = 10000000000\n",
    "            for child in self.children(node):\n",
    "                next_node_value = self.minimax(child, depth-1)\n",
    "                if next_node_value < current_node_value:\n",
    "                    current_node_value = next_node_value\n",
    "            node[\"value\"] = current_node_value\n",
    "            return current_node_value\n",
    "\n",
    "        \n",
    "    def ab_minimax(self, node, depth, min_val, max_val):\n",
    "        \"\"\" \n",
    "        Implementation of Minimax with Alpha Beta Pruning\n",
    "        \n",
    "        In contrast to previous minimax algorithm, must now input min_val and max_val as well\n",
    "        \"\"\"\n",
    "        if self.leaf(node) or depth == 0:\n",
    "            return self.evaluate(node)\n",
    "        \n",
    "        if self.max_node(node):\n",
    "            current_node_value = min_val\n",
    "            for child in self.children(node):\n",
    "                next_node_value = self.ab_minimax(child, depth-1, current_node_value, max_val)\n",
    "                if current_node_value < next_node_value:\n",
    "                    current_node_value = next_node_value\n",
    "                if current_node_value > max_val:\n",
    "                    return max_val\n",
    "            node[\"value\"] = current_node_value\n",
    "            return current_node_value\n",
    "        \n",
    "        if not self.max_node(node):\n",
    "            current_node_value = max_val\n",
    "            for child in self.children(node):\n",
    "                next_node_value = self.ab_minimax(child, depth-1, min_val, current_node_value)\n",
    "                if next_node_value < current_node_value:\n",
    "                    current_node_value = next_node_value\n",
    "                if current_node_value < min_val:\n",
    "                    return min_val\n",
    "            node[\"value\"] = current_node_value\n",
    "            return current_node_value\n",
    "        \n",
    "    def calc_next_move(self):\n",
    "        \"\"\"\n",
    "        Calculate Minimax's Learners optimal next move\n",
    "        \"\"\"\n",
    "        current_tree = self.create_tree(self.board, self.depth, self.player, None)\n",
    "        \n",
    "        if self.alg == \"minimax\":\n",
    "            top_val = self.minimax(current_tree, self.depth)\n",
    "        elif self.alg == \"ab\":\n",
    "            top_val = self.ab_minimax(current_tree, self.depth, -100000, 100000)\n",
    "                            \n",
    "        for child in current_tree[\"children\"]:\n",
    "            if child[\"value\"] == top_val:\n",
    "                return child[\"move\"]\n",
    "        \n",
    "        top_val = np.min([x[\"value\"] for x in current_tree[\"children\"]])\n",
    "        for child in current_tree[\"children\"]:\n",
    "            if child[\"value\"] == top_val:\n",
    "                return child[\"move\"]    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
