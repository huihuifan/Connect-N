{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run simulations and plots - Andre"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from __future__ import division, print_function\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import cPickle as pickle\n",
    "\n",
    "from helpers import *\n",
    "from agents import *\n",
    "from simulator import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1.5 s, sys: 6.44 ms, total: 1.51 s\n",
      "Wall time: 1.53 s\n",
      "634 366 0\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "Test\n",
    "'''\n",
    "\n",
    "x = ConnectN(5, 3)\n",
    "p1 = Random_Learner(x) \n",
    "#p2 = MCTS(x, 100,0.5)\n",
    "#p2 = Extend_Learner(x, 4, 5, -1) \n",
    "p2 = Random_Learner(x) \n",
    "\n",
    "%time p1_wins, p2_wins, draws, history = run_many_games(x, p1, p2, 1000)\n",
    "print(p1_wins, p2_wins, draws)\n",
    "#print(history)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random vs. Random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Outcomes:  5607 4391 2\n",
      "Player 1 Win-rate:  0.5607\n",
      "Player 2 Win-rate:  0.4391\n",
      "Draw-rate:  0.0002\n"
     ]
    }
   ],
   "source": [
    "board_1 = ConnectN(7, 4)\n",
    "Random_1 = Random_Learner(board_1) \n",
    "Random_2 = Random_Learner(board_1) \n",
    "rVr_games = 10000\n",
    "rVr_p1wins, rVr_p2wins, rVr_draws, rVr_history = run_many_games(board_1, Random_1, Random_2, rVr_games)\n",
    "print(\"Outcomes: \", rVr_p1wins, rVr_p2wins, rVr_draws)\n",
    "print(\"Player 1 Win-rate: \", rVr_p1wins/rVr_games)\n",
    "print(\"Player 2 Win-rate: \", rVr_p2wins/rVr_games)\n",
    "print(\"Draw-rate: \", rVr_draws/rVr_games)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random vs. MCTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "board_1 = ConnectN(7, 4)\n",
    "Random_Agent = Random_Learner(board_1) \n",
    "MCTS_Agent = Random_Learner(board_1) \n",
    "RvMCTS_games = 100\n",
    "RvMCTS_p1wins, RvMCTS_p2wins, RvMCTS_draws, RvMCTS_history = run_many_games(board_1, Random_Agent, MCTS_Agent, RvMCTS_games)\n",
    "print(\"Outcomes: \", RvMCTS_p1wins, RvMCTS_p2wins, RvMCTS_draws)\n",
    "print(\"Player 1 Win-rate: \", RvMCTS_p1wins/RvMCTS_games)\n",
    "print(\"Player 2 Win-rate: \", RvMCTS_p2wins/RvMCTS_games)\n",
    "print(\"Draw-rate: \", RvMCTS_draws/RvMCTS_games)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train Q-Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def train_Q_learner(num_trials = 1000, k=2, n=4, grid_size = 7):\n",
    "    \"\"\"\n",
    "    Trains the Q Learner against Random\n",
    "    \n",
    "    Inputs:\n",
    "    Number of games to play\n",
    "    On grid_size x\n",
    "    N tokens to connect\n",
    "    \n",
    "    Outputs:\n",
    "    Q Learner value table after training\n",
    "    \"\"\"\n",
    "    depth = k\n",
    "    N = n\n",
    "    grid_size = grid_size\n",
    "    x = ConnectN(grid_size, N)\n",
    "    history = []\n",
    "    \n",
    "    p1 = Random_Learner(x)\n",
    "    p2 = Q_Learner(x, None, None, player=-1)\n",
    "    winner = play_game_no_output(x, p1, p2)\n",
    "    history.append(winner)\n",
    "    \n",
    "    for game in xrange(1, num_trials):\n",
    "                \n",
    "        x = ConnectN(grid_size, N)\n",
    "        p1 = Q_Learner(x, p2.value_table, None, player=-1)\n",
    "        p2 = Random_Learner(x)\n",
    "        winner = play_game_no_output(x, p1, p2)\n",
    "        history.append(winner)\n",
    "\n",
    "        if game == num_trials - 1:\n",
    "            return p1.value_table, history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Input must >= 2-d.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-3c99542d10ad>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mv_table\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhistory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_Q_learner\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_trials\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrid_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m7\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-4-3b182422c0bd>\u001b[0m in \u001b[0;36mtrain_Q_learner\u001b[0;34m(num_trials, k, n, grid_size)\u001b[0m\n\u001b[1;32m     19\u001b[0m     \u001b[0mp1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mRandom_Learner\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m     \u001b[0mp2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mQ_Learner\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mplayer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m     \u001b[0mwinner\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mplay_game_no_output\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mp1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mp2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m     \u001b[0mhistory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwinner\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/TaisMBP13/Desktop/Dropbox/Harvard/Spring2015/CS282/final/Connect-N/helpers.pyc\u001b[0m in \u001b[0;36mplay_game_no_output\u001b[0;34m(board, p1, p2)\u001b[0m\n\u001b[1;32m     35\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mp1result\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 37\u001b[0;31m         \u001b[0mp2move\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mp2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcalc_next_move\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreward\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mboard\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     38\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mp2move\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/TaisMBP13/Desktop/Dropbox/Harvard/Spring2015/CS282/final/Connect-N/agents.py\u001b[0m in \u001b[0;36mcalc_next_move\u001b[0;34m(self, reward, next_board_state)\u001b[0m\n\u001b[1;32m    479\u001b[0m         \u001b[0;31m# Update value function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    480\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 481\u001b[0;31m         \u001b[0mdelta\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mreward\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdiscount_factor\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mamax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalue_table\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mgrid_to_key\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnext_board_state\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalue_table\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mgrid_to_key\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlast_board_state\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlast_action\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    482\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalue_table\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mgrid_to_key\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlast_board_state\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlast_action\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlearning_rate\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mdelta\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    483\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/TaisMBP13/Desktop/Dropbox/Harvard/Spring2015/CS282/final/Connect-N/agents.py\u001b[0m in \u001b[0;36mgrid_to_key\u001b[0;34m(grid)\u001b[0m\n\u001b[1;32m    342\u001b[0m     \u001b[0mkey\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    343\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 344\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mrow\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrot90\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgrid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    345\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mcolumn\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrow\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    346\u001b[0m             \u001b[0mkey\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcolumn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/TaisMBP13/anaconda/lib/python2.7/site-packages/numpy/lib/twodim_base.pyc\u001b[0m in \u001b[0;36mrot90\u001b[0;34m(m, k)\u001b[0m\n\u001b[1;32m    175\u001b[0m     \u001b[0mm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0masanyarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mm\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    176\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 177\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Input must >= 2-d.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    178\u001b[0m     \u001b[0mk\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mk\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;36m4\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    179\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mk\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Input must >= 2-d."
     ]
    }
   ],
   "source": [
    "v_table, history = train_Q_learner(num_trials = 1000, k=2, n=4, grid_size = 7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# save stuff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'Extend_Learner' object has no attribute 'value_table'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-f8334aed41b6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;31m# save Q_Learner state\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'data.p'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'wb'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mfp\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m     \u001b[0mpickle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdump\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mQAgent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalue_table\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'data.p'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'rb'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mfp\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'Extend_Learner' object has no attribute 'value_table'"
     ]
    }
   ],
   "source": [
    "'''\n",
    "broken\n",
    "'''\n",
    "\n",
    "board_2 = ConnectN(7, 4)\n",
    "Random = Random_Learner(board_2)\n",
    "QAgent = Q_Learner(board_2, None, None, player=-1)\n",
    "#QAgent = Extend_Learner(board_2, 4, 5, -1) \n",
    "Q_games = 4\n",
    "\n",
    "Q_p1wins, Q_p2wins, Q_draws, Q_history = run_many_games(board_2, Random, QAgent, Q_games)\n",
    "\n",
    "# save Q_Learner state\n",
    "with open('data.p', 'wb') as fp:\n",
    "    pickle.dump(QAgent.value_table, fp)\n",
    "    \n",
    "with open('data.p', 'rb') as fp:\n",
    "    data = pickle.load(fp)\n",
    "    \n",
    "print(QAgent.value_table)\n",
    "\n",
    "print(data)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
