{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Andre's Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from __future__ import division\n",
    "import numpy as np\n",
    "from numpy.random import rand\n",
    "import math\n",
    "from random import randint\n",
    "import itertools\n",
    "import random\n",
    "import copy\n",
    "from copy import deepcopy \n",
    "from multiprocessing import Pool\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Ken's break ties function.\n",
    "def argmax_breaking_ties_randomly(x):\n",
    "    max_value = np.max(x)\n",
    "    indices_with_max_value = np.flatnonzero(x == max_value)\n",
    "    return np.random.choice(indices_with_max_value)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simulator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class ConnectN:\n",
    "    \"\"\"\n",
    "    Connect N game simulator for two players, 1 and -1.\n",
    "    \n",
    "    Inputs:\n",
    "    Grid size- creates a grid size x grid size square board\n",
    "    N- number of tokens a player must connect to win the game\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, grid_size, n):\n",
    "        self.n = n\n",
    "        self.grid_size = grid_size\n",
    "        self.grid = np.zeros([grid_size,grid_size])\n",
    "        self.finished = 0\n",
    "        self.turn_num = 0\n",
    "        \n",
    "    def reset(self):\n",
    "        self.__init__(self.grid_size, self.n)\n",
    "\n",
    "    def check_win(self, col, row, player):\n",
    "        \"\"\"\n",
    "        Checks if given player has connected N tokens.\n",
    "        \"\"\"\n",
    "        for i in range(0, self.n):\n",
    "            if sum(self.grid[col, row - i:row - i + self.n]) == self.n*player:\n",
    "                self.finished = 1\n",
    "                return 1\n",
    "            if sum(self.grid[col - i: col - i + self.n, row]) == self.n*player:\n",
    "                self.finished = 1\n",
    "                return 1\n",
    "            if col - i >= 0 and col - i + self.n - 1 < self.grid_size and row - i >= 0 and row - i + self.n - 1 < self.grid_size:\n",
    "                if sum([self.grid[col - i + x, row - i + x] for x in range(0, self.n)]) == self.n*player:\n",
    "                    self.finished = 1\n",
    "                    return 1\n",
    "            if col - i >= 0 and col - i + self.n - 1 < self.grid_size and row + i >= self.n - 1 and row + i < self.grid_size:\n",
    "                if sum([self.grid[col - i + x, row + i - x] for x in range(0, self.n)]) == self.n*player:\n",
    "                    self.finished = 1\n",
    "                    return 1\n",
    "        return 0\n",
    "\n",
    "    def move(self, col, player):\n",
    "        \"\"\"\n",
    "        Given player and column to move in, modifies board and increments the turn counter.\n",
    "        \n",
    "        Returns a tuple, where first value is return message and second value is reward.\n",
    "        \"\"\"\n",
    "        self.turn_num += 1\n",
    "        \n",
    "        if self.finished == 1:\n",
    "            return 1, 50\n",
    "        sum_col = np.sum([abs(x) for x in self.grid[col]])\n",
    "        if sum_col == self.grid_size:\n",
    "            return -1, -1\n",
    "        self.grid[col, sum_col] = player\n",
    "        if self.check_win(col, sum_col, player) == 1:\n",
    "            return 1, 50\n",
    "        return 0, 0\n",
    "    \n",
    "    def turn(self):\n",
    "        \"\"\"\n",
    "        Returns which player's turn it is. First turn is player 1, second turn is player -1.\n",
    "        \"\"\"\n",
    "        if self.turn_num%2 == 0:\n",
    "            return 1\n",
    "        else:\n",
    "            return -1\n",
    "        \n",
    "    def next_possible_moves(self):\n",
    "        \"\"\"\n",
    "        Returns array of possible columns for a next move\n",
    "        \"\"\"\n",
    "        columns = []\n",
    "        \n",
    "        for i in xrange(0, self.grid_size):\n",
    "            if (0 in self.grid[i]):\n",
    "                columns.append(i)\n",
    "                \n",
    "        return columns\n",
    "    \n",
    "    def all_tokens_placed(self):\n",
    "        \"\"\"\n",
    "        Returns location of all tokens (column, row) that have been placed\n",
    "        \"\"\"\n",
    "        all_tokens = []\n",
    "        \n",
    "        for col in xrange(0, self.grid_size):\n",
    "            for row in xrange(0, self.grid_size): \n",
    "                if self.grid[col][row] != 0:\n",
    "                    all_tokens.append({\"location\": [col, row], \"player\": self.grid[col][row]})\n",
    "                    \n",
    "        return all_tokens\n",
    "    \n",
    "    def is_empty(self, col, row):\n",
    "        \"\"\"\n",
    "        Returns if a given spot (column, row) is empty\n",
    "        \"\"\"\n",
    "        return self.grid[col][row] == 0\n",
    "    \n",
    "    \"\"\"\n",
    "    Following streak functions check if player has token streak in the four possible win directions\n",
    "    \"\"\"\n",
    "    def streakVertical(self, board, col, row, player):\n",
    "        if row > len(board[col]) - self.n:\n",
    "            return 0\n",
    "        for i in range(0,self.n):\n",
    "            if board[col][row + i] == -1*player:\n",
    "                return 0\n",
    "            if board[col][row + i] == 0:\n",
    "                return i\n",
    "        return self.n\n",
    "\n",
    "    def streakHorizontal(self, board, col, row, player):\n",
    "        if col > len(board) - self.n:\n",
    "            return 0\n",
    "        for i in range(0,self.n):\n",
    "            if board[col + i][row] == -1*player:\n",
    "                return 0\n",
    "            if board[col + i][row] == 0:\n",
    "                return i\n",
    "        return self.n\n",
    "    \n",
    "    def streakDiagonalUp(self, board, col, row, player):\n",
    "        if row > len(board[col]) - self.n or col > len(board) - self.n:\n",
    "            return 0\n",
    "        for i in range(0,self.n):\n",
    "            if board[col + i][row + i] == -1*player:\n",
    "                return 0\n",
    "            if board[col + i][row + i] == 0:\n",
    "                return i\n",
    "        return self.n\n",
    "    \n",
    "    def streakDiagonalDown(self, board, col, row, player):\n",
    "        if row < self.n or col > len(board) - self.n:\n",
    "            return 0\n",
    "        for i in range(0,self.n):\n",
    "            if board[col + i][row - i] == -1*player:\n",
    "                return 0\n",
    "            if board[col + i][row - i] == 0:\n",
    "                return i\n",
    "        return self.n\n",
    "    \n",
    "    def print_grid(self):\n",
    "        print(np.rot90(self.grid))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Play Game"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "'''\n",
    "MODIFIED TO (NOT PRINT) AND (RETURN INDICATOR OF WINNER) \n",
    "'''\n",
    "def play_game_mod(board, p1, p2, q=False):\n",
    "    \"\"\"\n",
    "    Runs Connect 4 game given simulator object and two agents (players)\n",
    "    q takes False, -1, 1 (integer indicating which player is Q-Learner)\n",
    "    Returns player number who has won\n",
    "    \"\"\"\n",
    "    reward = None\n",
    "    \n",
    "    if q == 1:\n",
    "        while True:\n",
    "            #print(\"p1\")\n",
    "            p1move = p1.interact(reward, board)\n",
    "            #print(p1move)\n",
    "            if (p1move is None):\n",
    "                board.print_grid()\n",
    "                print(\"error player 1 a\")\n",
    "                return -1, 0\n",
    "            p1result, reward = board.move(p1move, 1)\n",
    "            #print p1result\n",
    "            if (p1result == 1):\n",
    "                #print(\"player 1\")\n",
    "                #board.print_grid()\n",
    "                return 1, 1\n",
    "            elif (p1result == -1):\n",
    "                board.print_grid()\n",
    "                print(\"error player 1 b\")\n",
    "                return -1, 0\n",
    "            #print(\"p2\")\n",
    "            p2move = p2.calc_next_move()\n",
    "            #print(p2move)\n",
    "            if (p2move is None):\n",
    "                board.print_grid()\n",
    "                print(\"error player 2\")\n",
    "                return -1, 0 \n",
    "            p2result = board.move(p2move, -1)\n",
    "            #print p2result\n",
    "            if (p2result[0] == 1):\n",
    "                #print(\"player 2\")\n",
    "                #board.print_grid()\n",
    "                return 1, -1\n",
    "            elif (p2result[0] == -1):\n",
    "                board.print_grid()\n",
    "                print(\"error player 2\")\n",
    "                return -1, 0\n",
    "    elif q == -1:\n",
    "        while True:\n",
    "            #print(\"p1\")\n",
    "            p1move = p1.calc_next_move()\n",
    "            #print(p1move)\n",
    "            if (p1move is None):\n",
    "                board.print_grid()\n",
    "                print(\"error player 1 a\")\n",
    "                return -1, 0\n",
    "            p1result, reward = board.move(p1move, 1)\n",
    "            #print p1result\n",
    "            if (p1result == 1):\n",
    "                #print(\"player 1\")\n",
    "                #board.print_grid()\n",
    "                return 1, 1\n",
    "            elif (p1result == -1):\n",
    "                board.print_grid()\n",
    "                print(\"error player 1 b\")\n",
    "                return -1, 0\n",
    "            #print(\"p2\")\n",
    "            p2move = p2.interact(reward, board)\n",
    "            #print(p2move)\n",
    "            if (p2move is None):\n",
    "                board.print_grid()\n",
    "                print(\"error player 2\")\n",
    "                return -1, 0 \n",
    "            p2result = board.move(p2move, -1)\n",
    "            #print p2result\n",
    "            if (p2result[0] == 1):\n",
    "                #print(\"player 2\")\n",
    "                #board.print_grid()\n",
    "                return 1, -1\n",
    "            elif (p2result[0] == -1):\n",
    "                board.print_grid()\n",
    "                print(\"error player 2\")\n",
    "                return -1, 0\n",
    "    \n",
    "    else:\n",
    "        while True:\n",
    "            #print(\"p1\")\n",
    "            p1move = p1.calc_next_move()\n",
    "            #print(p1move, board.next_possible_moves())\n",
    "            #print(p1move)\n",
    "            if (p1move is None):\n",
    "                board.print_grid()\n",
    "                print(\"error 1\")\n",
    "                return -1, 0\n",
    "            p1result = board.move(p1move, 1)\n",
    "            #print p1result\n",
    "            if (p1result[0] == 1):\n",
    "                #print(\"player 1\")\n",
    "                #board.print_grid()\n",
    "                return 1, 1\n",
    "            elif (p1result[0] == -1):\n",
    "                board.print_grid()\n",
    "                print(\"error 2\")\n",
    "                return -1, 0\n",
    "            #print(\"p2\")\n",
    "            p2move = p2.calc_next_move()\n",
    "            #print(p2move, board.next_possible_moves())\n",
    "            #print(p2move)\n",
    "            if (p2move is None):\n",
    "                board.print_grid()\n",
    "                print(\"error 3\")\n",
    "                return -1, 0\n",
    "            p2result = board.move(p2move, -1)\n",
    "            #print p2result\n",
    "            if (p2result[0] == 1):\n",
    "                #print(\"player 2\")\n",
    "                #board.print_grid()\n",
    "                return 1, -1\n",
    "            elif (p2result[0] == -1):\n",
    "                board.print_grid()\n",
    "                print(\"error 4\")\n",
    "                return -1, 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Agents"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Minimax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Minimax with depth past 6 takes a long time to make a move, seems not necessary\n",
    "# Minimax depth 5 is \"hard\"\n",
    "# Minimax depth 3 is \"medium\"\n",
    "# Minimax depth 1 is \"easy\"\n",
    "\n",
    "class Minimax_Learner(object):\n",
    "    \"\"\"\n",
    "    Implementation of AI algorithm Minimax with static evaluator \n",
    "    \n",
    "    Inputs:\n",
    "    Connect N board\n",
    "    Depth- Minimax Learner will build tree of next possible moves to that depth\n",
    "    N- number of tokens that need to be connected for a player to win\n",
    "    Player- player number, either 1 or -1\n",
    "    Algorithm- either \"minimax\" or \"ab\" for alpha beta pruned minimax\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, board, depth, n, player, alg):\n",
    "        self.board = board\n",
    "        self.depth = depth\n",
    "        self.num_states = board.grid_size\n",
    "        self.player = player\n",
    "        self.n = n\n",
    "        self.alg = alg\n",
    "\n",
    "    def value(self, board):\n",
    "        \"\"\"\n",
    "        Calculates value of board states\n",
    "        \"\"\"\n",
    "        val = 0\n",
    "        conversion = [int(i*math.pow(2, i))/2 for i in range(0, self.n+1)]\n",
    "        conversion[self.n] = 20000000\n",
    "        conversion_other = [i*int(math.pow(2, i))/6 for i in range(0, self.n+1)]\n",
    "        conversion_other[self.n] = 1000000\n",
    "        for i in range(0, len(board)):\n",
    "            for j in range(0, len(board[0])):\n",
    "                temp = self.board.streakVertical(board, i, j, self.player)\n",
    "                if temp == self.n:\n",
    "                    return conversion[temp]\n",
    "                val += conversion[temp]\n",
    "                \n",
    "                temp = self.board.streakHorizontal(board, i, j, self.player)\n",
    "                if temp == self.n:\n",
    "                    return conversion[temp]\n",
    "                val += conversion[temp]    \n",
    "                \n",
    "                temp = self.board.streakDiagonalUp(board, i, j, self.player)\n",
    "                if temp == self.n:\n",
    "                    return conversion[temp]\n",
    "                val += conversion[temp]\n",
    "                \n",
    "                temp = self.board.streakDiagonalDown(board, i, j, self.player)\n",
    "                if temp == self.n:\n",
    "                    return conversion[temp]\n",
    "                val += conversion[temp]\n",
    "                \n",
    "                \n",
    "                temp = self.board.streakVertical(board, i, j, -1*self.player)\n",
    "                if temp == self.n:\n",
    "                    return -1*conversion_other[temp]\n",
    "                val -= conversion[temp]\n",
    "\n",
    "                temp = self.board.streakHorizontal(board, i, j, -1*self.player)\n",
    "                if temp == self.n:\n",
    "                    return -1*conversion_other[temp]\n",
    "                val -= conversion[temp]\n",
    "                temp = self.board.streakDiagonalUp(board, i, j, -1*self.player)\n",
    "                if temp == self.n:\n",
    "                    return -1*conversion_other[temp]\n",
    "                val -= conversion[temp]\n",
    "                temp = self.board.streakDiagonalDown(board, i, j, -1*self.player)\n",
    "                if temp == self.n:\n",
    "                    return -1*conversion_other[temp]\n",
    "                val -= conversion[temp]\n",
    "\n",
    "        return val\n",
    "        \n",
    "    def create_tree(self, node, depth, player, move):\n",
    "        \"\"\"\n",
    "        Creates tree of next possible moves\n",
    "        \n",
    "        Each node is a dict of node value, children, the board state, which player's turn it would be, and move\n",
    "        \"\"\"\n",
    "        if depth == 0:\n",
    "            return None\n",
    "        \n",
    "        else:\n",
    "            tree = {\"value\": 0, \"children\": [], \"board\": node, \"player\": player, \"move\": move}\n",
    "\n",
    "            next_moves = node.next_possible_moves()\n",
    "\n",
    "            for move in next_moves:\n",
    "                board_copy = copy.deepcopy(node)\n",
    "                board_copy.move(move, player)\n",
    "                new_child = self.create_tree(board_copy, depth-1, -1*player, move)\n",
    "                \n",
    "                if new_child != None:\n",
    "                    tree[\"children\"].append(new_child)\n",
    "\n",
    "            return tree\n",
    "\n",
    "    def children(self, node):\n",
    "        \"\"\" \n",
    "        returns children of a node\n",
    "        \"\"\"\n",
    "        return node[\"children\"]\n",
    "   \n",
    "    def leaf(self, node):\n",
    "        \"\"\"\n",
    "        returns if current node is a leaf (i.e. no children)\n",
    "        \"\"\"\n",
    "        return len(self.children(node)) == 0\n",
    "        \n",
    "    def max_node(self, node):\n",
    "        \"\"\"\n",
    "        returns true if node is a max node\n",
    "        \"\"\"\n",
    "        return node[\"player\"] == self.player\n",
    "        \n",
    "    def evaluate(self, node):\n",
    "        \"\"\"\n",
    "        Static evaluator function to return a value between Loss and Win for intermediate game\n",
    "        positions, larger if the position is better for the current player.\n",
    "        If depth limit of the search is exceeded, is applied to remaining nodes as if\n",
    "        they were leaves. \n",
    "        \n",
    "        We calculate the rating by checking each token already placed, and \n",
    "        checking how many possible ways to connect N there are\n",
    "        \"\"\"\n",
    "        node[\"value\"] = self.value(node[\"board\"].grid)\n",
    "        return node[\"value\"]       \n",
    "\n",
    "    def minimax(self, node, depth):\n",
    "        \"\"\" \n",
    "        Recursive implementation of Minimax algorithm using pseudocode from: \n",
    "        https://www.cs.cornell.edu/courses/cs312/2002sp/lectures/rec21.htm\n",
    "        \"\"\"\n",
    "        if self.leaf(node) or depth == 0:\n",
    "            return self.evaluate(node)\n",
    "        \n",
    "        if self.max_node(node):\n",
    "            # L = -infinity\n",
    "            current_node_value = -1000000000\n",
    "            for child in self.children(node):\n",
    "                next_node_value = self.minimax(child, depth-1)\n",
    "                if current_node_value < next_node_value:\n",
    "                    current_node_value = next_node_value\n",
    "            node[\"value\"] = current_node_value\n",
    "            return current_node_value\n",
    "        \n",
    "        if not self.max_node(node):\n",
    "            # W = +infinity\n",
    "            current_node_value = 10000000000\n",
    "            for child in self.children(node):\n",
    "                next_node_value = self.minimax(child, depth-1)\n",
    "                if next_node_value < current_node_value:\n",
    "                    current_node_value = next_node_value\n",
    "            node[\"value\"] = current_node_value\n",
    "            return current_node_value\n",
    "\n",
    "        \n",
    "    def ab_minimax(self, node, depth, min_val, max_val):\n",
    "        \"\"\" \n",
    "        Implementation of Minimax with Alpha Beta Pruning\n",
    "        \n",
    "        In contrast to previous minimax algorithm, must now input min_val and max_val as well\n",
    "        \"\"\"\n",
    "        if self.leaf(node) or depth == 0:\n",
    "            return self.evaluate(node)\n",
    "        \n",
    "        if self.max_node(node):\n",
    "            current_node_value = min_val\n",
    "            for child in self.children(node):\n",
    "                next_node_value = self.ab_minimax(child, depth-1, current_node_value, max_val)\n",
    "                if current_node_value < next_node_value:\n",
    "                    current_node_value = next_node_value\n",
    "                if current_node_value > max_val:\n",
    "                    return max_val\n",
    "            node[\"value\"] = current_node_value\n",
    "            return current_node_value\n",
    "        \n",
    "        if not self.max_node(node):\n",
    "            current_node_value = max_val\n",
    "            for child in self.children(node):\n",
    "                next_node_value = self.ab_minimax(child, depth-1, min_val, current_node_value)\n",
    "                if next_node_value < current_node_value:\n",
    "                    current_node_value = next_node_value\n",
    "                if current_node_value < min_val:\n",
    "                    return min_val\n",
    "            node[\"value\"] = current_node_value\n",
    "            return current_node_value\n",
    "        \n",
    "    def calc_next_move(self):\n",
    "        \"\"\"\n",
    "        Calculate Minimax's Learners optimal next move\n",
    "        \"\"\"\n",
    "        current_tree = self.create_tree(self.board, self.depth, self.player, None)\n",
    "        \n",
    "        if self.alg == \"minimax\":\n",
    "            top_val = self.minimax(current_tree, self.depth)\n",
    "        elif self.alg == \"ab\":\n",
    "            top_val = self.ab_minimax(current_tree, self.depth, -100000, 100000)\n",
    "            \n",
    "        print \"this is top_val\", top_val\n",
    "                \n",
    "        for child in current_tree[\"children\"]:\n",
    "            if child[\"value\"] == top_val:\n",
    "                print \"i'm here\"\n",
    "                return child[\"move\"]\n",
    "        \n",
    "        top_val = np.min([x[\"value\"] for x in current_tree[\"children\"]])\n",
    "        for child in current_tree[\"children\"]:\n",
    "            if child[\"value\"] == top_val:\n",
    "                print \"i'm here\"\n",
    "                return child[\"move\"]    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Random_Learner(object):\n",
    "    \"\"\"\n",
    "    Implementation of Connect 4 agent that takes random moves at each action step\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, board):\n",
    "        self.board = board\n",
    "        \n",
    "\n",
    "    def calc_next_move(self):\n",
    "        moves = self.board.next_possible_moves()\n",
    "        return moves[random.randint(0, len(moves) - 1)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Naive Extending Learner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Extend_Learner(object):\n",
    "    \"\"\"\n",
    "    Implementation of naive algorithm that tries to extend longest streak. Prioritizes vertical streaks.\n",
    "    \n",
    "    Inputs:\n",
    "    Connect N board\n",
    "    Depth- Minimax Learner will build tree of next possible moves to that depth\n",
    "    N- number of tokens that need to be connected for a player to win\n",
    "    Player- player number, either 1 or -1\n",
    "    Algorithm- either \"minimax\" or \"ab\" for alpha beta pruned minimax\n",
    "\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, board, depth, n, player):\n",
    "        self.board = board\n",
    "        self.depth = depth\n",
    "        self.num_states = board.grid_size\n",
    "        self.player = player\n",
    "        self.n = n\n",
    "        \n",
    "\n",
    "    def get_max(self, d):\n",
    "        maxval = max(d)\n",
    "        options = [x for x in range(0, len(d)) if d[x] == maxval]\n",
    "        return options[random.randint(0, len(options) - 1)]\n",
    "\n",
    "    def calc_next_move(self):\n",
    "        \"\"\"\n",
    "        Calculate Minimax's Learners optimal next move\n",
    "        \"\"\"\n",
    "        max_len = 0\n",
    "        board = self.board.grid\n",
    "        max_cols = [0 for i in range(0, len(board))]\n",
    "        \n",
    "        \n",
    "        for i in range(0, len(board)):\n",
    "            for j in range(0, len(board[0])):\n",
    "                temp_len = self.board.streakVertical(board, i, j, self.player)\n",
    "                if temp_len > max_len:\n",
    "                    max_len = temp_len\n",
    "                    max_cols = [0 for k in range(0, len(board))]\n",
    "                    max_cols[i] += 2\n",
    "                elif temp_len == max_len:\n",
    "                    max_cols[i] += 2\n",
    "                    \n",
    "                temp_len = self.board.streakHorizontal(board, i, j, self.player)\n",
    "                if temp_len > max_len:\n",
    "                    max_len = temp_len\n",
    "                    max_cols = [0 for k in range(0, len(board))]\n",
    "                    max_cols[i + temp_len] += 1\n",
    "                elif temp_len == max_len:\n",
    "                    max_cols[i + temp_len] += 1\n",
    "\n",
    "                temp_len = self.board.streakDiagonalUp(board, i, j, self.player)\n",
    "                if temp_len > max_len:\n",
    "                    max_len = temp_len\n",
    "                    max_cols = [0 for k in range(0, len(board))]\n",
    "                    max_cols[i + temp_len] += 1\n",
    "                elif temp_len == max_len:\n",
    "                    max_cols[i + temp_len] += 1\n",
    "                \n",
    "                temp_len = self.board.streakDiagonalDown(board, i, j, self.player)\n",
    "                if temp_len > max_len:\n",
    "                    max_len = temp_len\n",
    "                    max_cols = [0 for k in range(0, len(board))]\n",
    "                    max_cols[i + temp_len] += 1\n",
    "                elif temp_len == max_len:\n",
    "                    max_cols[i + temp_len] += 1\n",
    "        \n",
    "        return self.get_max(max_cols)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q-Learner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def grid_to_key(grid):\n",
    "    \"\"\"\n",
    "    Converts ConnectN grid into string for dict indexing\n",
    "    \"\"\"\n",
    "\n",
    "    key = \"\"\n",
    "\n",
    "    for row in np.rot90(grid):\n",
    "        for column in row:\n",
    "            key += str(int(column))\n",
    "\n",
    "    return key\n",
    "\n",
    "\n",
    "class ConnectDict(dict):\n",
    "    \"\"\"\n",
    "    Creates a Custom Dict that inherits from Python's native dict.\n",
    "    Takes in a number of states.\n",
    "    Adds keys to dict each time lookup is necessary to avoid full dict initialization.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, num_states, *arg, **kw):\n",
    "        self.num_states = num_states\n",
    "        super(ConnectDict, self).__init__(*arg, **kw)\n",
    "        \n",
    "    def __getitem__(self, key):\n",
    "        if not dict.__contains__(self, key):\n",
    "            dict.__setitem__(self, key, np.zeros(self.num_states))\n",
    "        return dict.__getitem__(self, key)\n",
    "    \n",
    "\n",
    "class TD_Learner(object):\n",
    "    \"\"\"\n",
    "    Base class for Temporal Difference Learners, like Sarsa and Q learning.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, task, value_table=None, epsilon=.1, discount_factor=.9, learning_rate=.5, player=1, trace_size=.1):\n",
    "        \n",
    "        self.num_states = task.grid_size\n",
    "        self.num_actions = task.grid_size\n",
    "        self.epsilon = epsilon\n",
    "        self.discount_factor = discount_factor\n",
    "        self.learning_rate = learning_rate\n",
    "        \n",
    "        if value_table == None:\n",
    "            self.value_table = ConnectDict(self.num_states)\n",
    "        else:\n",
    "            self.value_table = value_table\n",
    "            \n",
    "        self.e = ConnectDict(self.num_states)\n",
    "        self.player = player\n",
    "        self.trace_size = trace_size\n",
    "        self.last_board_state = None\n",
    "        self.last_action = None\n",
    "\n",
    "#     def reset(self):\n",
    "#         self.last_board_state = None\n",
    "#         self.last_action = None\n",
    "    \n",
    "    def softmax(self, next_board_state):\n",
    "        \"\"\"\n",
    "        Implementation of Softmax Policy, which weights towards better actions rather\n",
    "        than sampling uniformly across all possible actions (epsilon-greedy)\n",
    "        \"\"\"\n",
    "        \n",
    "        def weighted_pick(weights,n_picks):\n",
    "            t = np.cumsum(weights)\n",
    "            s = sum(weights)\n",
    "            return np.searchsorted(t,rand(n_picks)*s)\n",
    "        \n",
    "        tau = .5\n",
    "        key_val = grid_to_key(next_board_state.grid)\n",
    "        \n",
    "        vals = self.value_table[key_val]\n",
    "        num = ([math.e**(float(x)/tau) for x in vals])\n",
    "        \n",
    "        probs = [x/sum(num) for x in num]\n",
    "        best_action = weighted_pick(probs, 1)\n",
    "\n",
    "        return best_action[0]\n",
    "    \n",
    "    \n",
    "class Q_Learner(TD_Learner):\n",
    "    \"\"\"\n",
    "    Implementation of Q Learning, inheriting from TD Learner base class. \n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, task, value_table, known_states, epsilon=.1, discount_factor=.9, learning_rate=.5, player=1, trace_size=.1):   \n",
    "        TD_Learner.__init__(self, task, value_table, epsilon, discount_factor, learning_rate, player, trace_size) \n",
    "        self.known_states = known_states\n",
    "        \n",
    "\n",
    "    def interact(self, reward, next_board_state):\n",
    "        if reward is None:\n",
    "            # Approximation of known states. Since too many states, instead, given a board position, \n",
    "            # explore possible moves and give 15 reward to creating streaks of length 3 or 4 and \n",
    "            # 20 reward for preventing an opponent win.\n",
    "            if (self.known_states):\n",
    "                for col in task.next_possible_moves():\n",
    "                    row = np.sum([abs(x) for x in next_board_state.grid[col]])\n",
    "                    if next_board_state.streakVertical(next_board_state.grid, col, row - 2, self.player) >= 2:\n",
    "                        self.value_table[grid_to_key(next_board_state.grid)][col] = 15\n",
    "                    temp_board = deepcopy(next_board_state.grid)\n",
    "                    temp_board[col][row] = self.player\n",
    "                    for i in range(0, 4):\n",
    "                        if next_board_state.streakHorizontal(temp_board, col - i, row, self.player) >= 3:\n",
    "                            self.value_table[grid_to_key(next_board_state.grid)][col] = 15\n",
    "                        if next_board_state.streakDiagonalUp(temp_board, col - i, row - i, self.player) >= 3:\n",
    "                            self.value_table[grid_to_key(next_board_state.grid)][col] = 15\n",
    "                        if next_board_state.streakDiagonalDown(temp_board, col - i, row + i, self.player) >= 3:\n",
    "                            self.value_table[grid_to_key(next_board_state.grid)][col] = 15\n",
    "                            \n",
    "                    if next_board_state.streakVertical(next_board_state.grid, col, row - 3, -self.player) == 3:\n",
    "                        self.value_table[grid_to_key(next_board_state.grid)][col] = 20\n",
    "                    temp_board = deepcopy(next_board_state.grid)\n",
    "                    temp_board[col][row] = -1*self.player\n",
    "                    for i in range(0, 4):\n",
    "                        if next_board_state.streakHorizontal(temp_board, col - i, row, -1*self.player) == 4:\n",
    "                            self.value_table[grid_to_key(next_board_state.grid)][col] = 20\n",
    "                        if next_board_state.streakDiagonalUp(temp_board, col - i, row - i, -1*self.player) == 4:\n",
    "                            self.value_table[grid_to_key(next_board_state.grid)][col] = 20\n",
    "                        if next_board_state.streakDiagonalDown(temp_board, col - i, row + i, -1*self.player) == 4:\n",
    "                            self.value_table[grid_to_key(next_board_state.grid)][col] = 20\n",
    "\n",
    "            next_action = self.softmax(next_board_state)\n",
    "\n",
    "            self.last_board_state = next_board_state.grid\n",
    "            self.last_action = next_action\n",
    "            return self.last_action\n",
    "                \n",
    "        if reward == 50:\n",
    "            delta = delta = reward - self.value_table[grid_to_key(self.last_board_state)][self.last_action]\n",
    "            self.value_table[grid_to_key(self.last_board_state)][self.last_action] += self.learning_rate * delta\n",
    "            \n",
    "            return self.last_action\n",
    "        \n",
    "        \"\"\"\n",
    "        VDBE-Softmax policy. If draw < epsilon, perform Softmax. Else do best action.\n",
    "        \"\"\"\n",
    "        draw = np.random.uniform(0,1,1)\n",
    "\n",
    "        if draw < self.epsilon:\n",
    "            next_action = self.softmax(next_board_state)\n",
    "        else:\n",
    "            next_action = np.argmax(self.value_table[grid_to_key(next_board_state.grid)])\n",
    "\n",
    "        # Update value function.\n",
    "        delta = reward + self.discount_factor * np.amax(self.value_table[grid_to_key(next_board_state.grid)]) - self.value_table[grid_to_key(self.last_board_state)][self.last_action]\n",
    "        self.value_table[grid_to_key(self.last_board_state)][self.last_action] += self.learning_rate * delta\n",
    "        \n",
    "        # Update eligibility traces (Watson's Q(lambda))\n",
    "        self.e[grid_to_key(self.last_board_state)][self.last_action] += 1\n",
    "\n",
    "        # Eligibility traces\n",
    "        # Note that here we do not implement classic eligibility traces, which iterate over all state, action pairs\n",
    "        # Instead we consider all next possible board states and update those (for easier computation)\n",
    "        next_possible_moves = next_board_state.next_possible_moves()\n",
    "        next_possible_boards = []\n",
    "        \n",
    "        for i in next_possible_moves:\n",
    "            temp_board = deepcopy(next_board_state)\n",
    "            temp_board.move(next_action, self.player)\n",
    "            next_possible_boards.append(temp_board)\n",
    "            \n",
    "        for board in next_possible_boards:\n",
    "            valid_actions = board.next_possible_moves()\n",
    "            for action in valid_actions:\n",
    "                self.value_table[grid_to_key(board.grid)][action] += self.learning_rate * delta \\\n",
    "                                                                    * self.e[grid_to_key(board.grid)][action]\n",
    "                if self.last_action == action:\n",
    "                    self.e[grid_to_key(board.grid)][action] = self.discount_factor * self.trace_size \\\n",
    "                                                                    * self.e[grid_to_key(board.grid)][action]\n",
    "                else:\n",
    "                    self.e[grid_to_key(board.grid)][action] = 0\n",
    "                    \n",
    "        self.last_board_state = next_board_state.grid\n",
    "        self.last_action = next_action\n",
    "\n",
    "        if next_board_state.simulate_move(self.last_action, self.player) == 1:\n",
    "            self.last_action = self.softmax(next_board_state)\n",
    "            \n",
    "        return self.last_action\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MCTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Node(object):\n",
    "    \"\"\"\n",
    "    Define a Tree Data Structure for MCTS\n",
    "    \"\"\"\n",
    "    def __init__(self, state, parent, action_taken):\n",
    "        self.state = state\n",
    "        self.parent = parent\n",
    "        self.actions = []\n",
    "        self.action_taken = action_taken\n",
    "        self.children = []\n",
    "        self.total_reward = 0\n",
    "        self.total_visit_count = 0.000001\n",
    "        \n",
    "        \n",
    "class MCTS(object):\n",
    "    \"\"\"\n",
    "    Monte Carlo Tree Search \n",
    "    UCT algorithm from \"A Survey of Monte Carlo Tree Search Methods\"\n",
    "    \n",
    "    Node is Agent's move, next move is enemy\n",
    "    \"\"\"    \n",
    "    def __init__(self, board, max_iter, C):\n",
    "        self.board = board\n",
    "        self.max_iter = max_iter\n",
    "        self.C = C\n",
    "        \n",
    "    def reset(self):\n",
    "        self.__init__(self.max_iter, self.C)\n",
    "        \n",
    "    def calc_next_move(self):\n",
    "        return self.uct_search(self.board)\n",
    "        \n",
    "    def full_check_win(self,board):\n",
    "        for col in xrange(0,board.grid_size):\n",
    "            for row in xrange(0,board.grid_size):\n",
    "                if board.check_win(col, row, 1) == 1:\n",
    "                    return True\n",
    "                if board.check_win(col, row, -1) == 1:\n",
    "                    return True\n",
    "        return False\n",
    "        \n",
    "    def uct_search(self,board):\n",
    "        # check for immediate win\n",
    "        for i in board.next_possible_moves():\n",
    "            b2 = copy.deepcopy(board)\n",
    "            if b2.turn() == 1:\n",
    "                b2.move(i, 1)\n",
    "                if self.full_check_win(b2):\n",
    "                    return i\n",
    "            if b2.turn() == -1:\n",
    "                b2.move(i, -1)\n",
    "                if self.full_check_win(b2):\n",
    "                    return i\n",
    "        # regular uct_search\n",
    "        iterator = 0\n",
    "        root = Node(board, None, None)\n",
    "        while iterator < self.max_iter:\n",
    "            c_node = self.tree_policy(root)\n",
    "            d = self.default_policy(c_node.state)\n",
    "            self.backup(c_node,d)\n",
    "            iterator = iterator + 1\n",
    "        return self.best_child(root,0)[0]\n",
    "        \n",
    "    def tree_policy(self,node):\n",
    "        x = node\n",
    "        while self.full_check_win(x.state) == False and x.state.next_possible_moves() != []:\n",
    "            if list(set(x.state.next_possible_moves()) - set(x.actions)) != []:\n",
    "                return self.expand(x)\n",
    "            else: \n",
    "                x = x.children[self.best_child(x,self.C)[1]]\n",
    "        return x\n",
    "    \n",
    "    def expand(self,node):\n",
    "        untried = list(set(node.state.next_possible_moves()) - set(node.actions))\n",
    "        if untried != []: \n",
    "            if node.state.turn() == 1:\n",
    "                child = copy.deepcopy(node)\n",
    "                child.state.move(untried[0],1)\n",
    "                node.children.append(Node(child.state, node, untried[0]))\n",
    "                node.actions.append(untried[0])\n",
    "                return node.children[-1]\n",
    "            if node.state.turn() == -1:\n",
    "                child = copy.deepcopy(node)\n",
    "                child.state.move(untried[0],-1)\n",
    "                node.children.append(Node(child.state, node, untried[0]))\n",
    "                node.actions.append(untried[0])\n",
    "                return node.children[-1]\n",
    "        return \n",
    "\n",
    "    \n",
    "    def best_child(self,node,c):\n",
    "        child_vals = [((x.total_reward)/(x.total_visit_count) + c * np.sqrt(2*np.log(node.total_visit_count)/x.total_visit_count)) for x in node.children]\n",
    "        best_inx = argmax_breaking_ties_randomly(child_vals)  \n",
    "        best_c = node.children[best_inx]\n",
    "        #print(child_vals)\n",
    "        return best_c.action_taken, best_inx\n",
    "        \n",
    "    def default_policy(self,board):\n",
    "        if board.turn() == 1:\n",
    "            # assumes that agent is player 1\n",
    "            board2 = copy.deepcopy(board)\n",
    "            if self.full_check_win(board2) == True:\n",
    "                return 50\n",
    "            while True:                \n",
    "                if board2.turn() == -1:\n",
    "                    # imagined enemy                        \n",
    "                    action2 = np.random.choice(board2.next_possible_moves())\n",
    "                    # check win\n",
    "                    for i in board2.next_possible_moves():\n",
    "                        b2 = copy.deepcopy(board2)\n",
    "                        b2.move(i, -1)\n",
    "                        if self.full_check_win(b2):\n",
    "                            action2 = i \n",
    "                    # else random\n",
    "                    board2.move(action2, -1)\n",
    "                    if self.full_check_win(board2) == True:\n",
    "                        return -50\n",
    "                    if board2.next_possible_moves() == []:\n",
    "                        return 0\n",
    "                # agent\n",
    "                if board2.turn() == 1:\n",
    "                    action = np.random.choice(board2.next_possible_moves())\n",
    "                    # check win\n",
    "                    for i in board2.next_possible_moves():\n",
    "                        b2 = copy.deepcopy(board2)\n",
    "                        b2.move(i, 1)\n",
    "                        if self.full_check_win(b2):\n",
    "                            action = i \n",
    "                    # else random\n",
    "                    board2.move(action, 1)\n",
    "                    if self.full_check_win(board2) == True:\n",
    "                        return 50\n",
    "                    if board2.next_possible_moves() == []:\n",
    "                        return 0        \n",
    "        if board.turn() == -1:\n",
    "            # assumes that agent is player -1\n",
    "            board2 = copy.deepcopy(board)\n",
    "            if self.full_check_win(board2) == True:\n",
    "                return 50\n",
    "            while True:\n",
    "                if board2.turn() == 1:\n",
    "                    # imagined enemy\n",
    "                    action2 = np.random.choice(board2.next_possible_moves())\n",
    "                    # check win\n",
    "                    for i in board2.next_possible_moves():\n",
    "                        b2 = copy.deepcopy(board2)\n",
    "                        b2.move(i, 1)\n",
    "                        if self.full_check_win(b2):\n",
    "                            action2 = i \n",
    "                    # else random\n",
    "                    board2.move(action2, 1)\n",
    "                    if self.full_check_win(board2) == True:\n",
    "                        return -50\n",
    "                    if board2.next_possible_moves() == []:\n",
    "                        return 0\n",
    "                # agent\n",
    "                if board2.turn() == -1:\n",
    "                    action = np.random.choice(board2.next_possible_moves())\n",
    "                    # check win\n",
    "                    for i in board2.next_possible_moves():\n",
    "                        b2 = copy.deepcopy(board2)\n",
    "                        b2.move(i, -1)\n",
    "                        if self.full_check_win(b2):\n",
    "                            action = i \n",
    "                    # else random\n",
    "                    board2.move(action, -1)\n",
    "                    if self.full_check_win(board2) == True:\n",
    "                        return 50\n",
    "                    if board2.next_possible_moves() == []:\n",
    "                        return 0\n",
    "            \n",
    "    def backup(self,node,d):\n",
    "        v = node \n",
    "        while v != None:\n",
    "            v.total_visit_count = v.total_visit_count + 1\n",
    "            v.total_reward = v.total_reward + d\n",
    "            v = v.parent\n",
    "        return\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Grid-Search to select exploration term"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def run_multiple_games(x, p1, p2, games):\n",
    "    \n",
    "\"\"\"\n",
    "OLD, see helpers.py for updated version\n",
    "\"\"\"\n",
    "    p1_wins = 0\n",
    "    p2_wins = 0\n",
    "    draws = 0\n",
    "    for i in xrange(0,games):\n",
    "        x.reset()\n",
    "        ret, winner = play_game_mod(x, p1, p2)\n",
    "        if winner == 1:\n",
    "            p1_wins = p1_wins + 1\n",
    "        if winner == -1:\n",
    "            p2_wins = p2_wins + 1 \n",
    "        if winner == 0:\n",
    "            draws = draws + 1\n",
    "        #print(winner)\n",
    "    #print(p1_wins, p2_wins, draws)\n",
    "    return p1_wins, p2_wins, draws\n",
    "\n",
    "def parallel_MCTS_explore(i):\n",
    "    games = 100\n",
    "    x = ConnectN(5, 3)\n",
    "    p1 = Random_Learner(x) \n",
    "    p2 = MCTS(x, 100,i)\n",
    "    #p2 = Random_Learner(x)\n",
    "    p1_wins, p2_wins, draws = run_multiple_games(x, p1, p2, games)\n",
    "    print(i)\n",
    "    return p2_wins/games\n",
    "\n",
    "\n",
    "def select_MCTS_exploreterm():\n",
    "    exp_term_range = np.array(range(0,21))/10.0\n",
    "    if __name__ == '__main__':\n",
    "        pool = Pool()  # start all workers\n",
    "        win_rate = pool.map(parallel_MCTS_explore, exp_term_range)\n",
    "        win_rate = np.array(win_rate)\n",
    "    return exp_term_range, win_rate\n",
    "\n",
    "\n",
    "# def select_MCTS_exploreterm():\n",
    "#     exp_term_range = np.array(range(0,11))/10.0\n",
    "#     games = 50\n",
    "#     win_rate = []\n",
    "#     for i in exp_term_range:\n",
    "#         x = ConnectN(8, 4)\n",
    "#         p1 = Random_Learner(x) \n",
    "#         p2 = MCTS(x, 500,i)\n",
    "#         #p2 = Random_Learner(x)\n",
    "#         p1_wins, p2_wins, draws = run_multiple_games(x, p1, p2, games)\n",
    "#         win_rate.append(p2_wins/games)\n",
    "#     return exp_term_range, win_rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0\n",
      "0.4\n",
      "0.2\n",
      "0.6\n",
      "0.10.50.30.7\n",
      "\n",
      "\n",
      "\n",
      "0.81.01.21.4\n",
      "\n",
      "\n",
      "\n",
      "0.91.11.31.5\n",
      "\n",
      "\n",
      "\n",
      "1.62.01.8\n",
      "\n",
      "\n",
      "1.71.9\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAY0AAAEZCAYAAABrUHmEAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nOE5qXGk4juM4qfn/GKR6hWjXuywAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x106c54bd0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Run Grid-Search\n",
    "params, scores = select_MCTS_exploreterm()\n",
    "plt.plot(params, scores)    \n",
    "plt.title('MCTS Exploration Term Grid Search')\n",
    "plt.xlabel('Exploration Term Value')\n",
    "plt.ylabel('Win-rate against Random_Learner')\n",
    "#plt.ylim(0,1)\n",
    "plt.grid()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAY0AAAEZCAYAAABrUHmEAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\ngg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x102031490>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(params, scores)    \n",
    "plt.title('MCTS Exploration Term Grid Search')\n",
    "plt.xlabel('Exploration Term Value')\n",
    "plt.ylabel('Win-rate against Random_Learner')\n",
    "plt.xlim(0,1)\n",
    "plt.grid()\n",
    "plt.savefig('MCTS_param.png', dpi=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 255 ms, sys: 9.17 ms, total: 264 ms\n",
      "Wall time: 263 ms\n",
      "(20, 80, 0)\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "Test\n",
    "'''\n",
    "\n",
    "x = ConnectN(5, 3)\n",
    "p1 = Random_Learner(x) \n",
    "#p2 = MCTS(x, 100,0.5)\n",
    "p2 = Extend_Learner(x, 4, 5, -1) \n",
    "#p2 = Random_Learner(x) \n",
    "\n",
    "%time p1_wins, p2_wins, draws = run_multiple_games(x, p1, p2, 100)\n",
    "print(p1_wins, p2_wins, draws)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Make Plots for Project"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plotting Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def run_multiple_games2(x, p1, p2, games, q=False):\n",
    "    p1_wins = 0\n",
    "    p2_wins = 0\n",
    "    draws = 0\n",
    "    history = []\n",
    "    for i in xrange(0,games):\n",
    "        x.reset()\n",
    "        ret, winner = play_game_mod(x, p1, p2, q)\n",
    "        history.append(winner)\n",
    "        if winner == 1:\n",
    "            p1_wins = p1_wins + 1\n",
    "        if winner == -1:\n",
    "            p2_wins = p2_wins + 1 \n",
    "        if winner == 0:\n",
    "            draws = draws + 1\n",
    "        #print(winner)\n",
    "    #print(p1_wins, p2_wins, draws)\n",
    "    return p1_wins, p2_wins, draws, history"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train Q-Learner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
